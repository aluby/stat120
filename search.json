[
  {
    "objectID": "activities/19-activity.html",
    "href": "activities/19-activity.html",
    "title": "19: CLT-based Inference for Proportions",
    "section": "",
    "text": "APM Research Lab ran a survey of likely Minnesota voters between Sept 16-18 of this year. They reported 48.4% in support of the Harris/Walz ticket, and 43.3% in support of the Trump/Vance ticket.\n\nHere’s an excerpt from their methodology report:\n\nThe margin for error, according to standards customarily used by statisticians, is no more than ± 3.5 percentage points. This means that there is a 95% probability that the “true” figure would fall within that range if all voters were surveyed.\n\n\nShow how the margin of error was computed\n\n\nIs it OK to use the normal distribution as a model for the sampling distribution of a proportion in this case?\n\n\nIn a random sample of 100 moviegoers in January 2013, 64 of them said they are more likely to wait and watch a new movie in the comfort of their own home.\n\n\nIs it ok to use the normal distribution as a model for the sampling distribution of the proportion of moviegoers preferring to wait and watch at home?\n\n\nSuppose I want to know if more than 50% of moviegoers in the population prefer to wait and watch at home. Write down the corresponding null and alternative hypotheses.\n\n\nFor the hypothesis test in part (b), find the standardized test statistic (i.e., the Z-score).\n\n\nCalculate the p-value and state a conclusion in context\n\n\nThe table below gives some of the percentiles of the N(0,1) distribution. If you were given this table (for example on an exam, where you do not have access to R), what could you say about the value of the p-value?\n\n\n\n\npercentage\npercentile (qnorm(percentage))\n\n\n\n\n90%\n1.3\n\n\n95%\n1.6\n\n\n97.5%\n2.0\n\n\n99%\n2.3\n\n\n99.5%\n2.6\n\n\n\n\nCompute and interpret a 90% confidence interval for the population proportion of moviegoers who believe they are more likely to watch a new movie from home. (Use the information from the previous table to find the critical value needed.)\n\n\nHow big of a sample size would you need if you wanted the margin of error for a 90% confidence interval to be no more than 2%? To answer this question, assume that the true proportion is \\(p=0.5\\), which would result in the biggest margin of error for a given sample size."
  },
  {
    "objectID": "activities/18-activity.html",
    "href": "activities/18-activity.html",
    "title": "18: The Normal Distribution",
    "section": "",
    "text": "Suppose weights of newborn babies in one community are normally distributed with a mean of 7.7 pounds and a standard deviation of 1.25 pounds\n1. Use the 95% rule to sketch a graph of this normal density curve. Include a scale with at least three values on the horizontal axis.\n2. Suppose I wanted to know the percent of newborns weighing less than 4.5 pounds.\n\nUse StatKey to answer this question\nUse the pnorm function to answer this question.\n\nAnswer: ________________\n3. Suppose I wanted to know the 15th percentile of the distribution.\n\nUse StatKey to answer this question\nUse the qnorm function to answer this question.\n\nAnswer: ________________\n4. APM Research Lab ran a survey of likely Minnesota voters between Sept 16-18 of this year. Here’s an excerpt from their methodology report:\n\nThe margin for error, according to standards customarily used by statisticians, is no more than ± 3.5 percentage points. This means that there is a 95% probability that the “true” figure would fall within that range if all voters were surveyed. The margin for error is higher for any subgroup, such as a gender or age grouping.\n\nThey reported 48.4% in support of the Harris/Walz ticket, and 43.3% in support of the Trump/Vance ticket.\n\nHow do you feel about this summary of a confidence interval (for a public/non-statistician audience)?\n\n\nWhat is the standard error for each of these estimates?\n\n\nBuild a 95% confidence interval for one of these proportions\n\n\nUse the normal distribution to instead build a 99% confidence interval for one of these proportions\n\nThe report also says:\n\nOverall margin of error = 3.5 percentage points (and therefore approximately 7 percentage points for the difference between two data points)\n\n\nUse this information to build a 90% confidence interval for the difference in proportions between the Harris/Walz supporters and the Trump/Vance supporters.\n\n5. True or False?\n\nThe central limit theorem says that the population distribution is approximately normal if the population is big enough.\nThe central limit theorem says that the sampling distribution for the mean of a random sample is approximately normal if the sample is big enough.\nThe central limit theorem says that the sampling distribution for the mean is only normal if the population distribution is normal.\nThe central limit theorem says that any statistic is normally distributed if the sample size is big enough.\nThe central limit theorem applies to proportions and means\n\n5. Using pnorm or qnorm, find the following quantities.\n\n\\(P(Z &lt; .25)\\)\n\\(P(Z &gt; 1.5)\\)\n\\(P(-.5 &lt; Z  &lt; 1.5)\\)\n\\(z^*\\) where \\(P(Z &lt; z^*) = .33\\)\n\\(z^*\\) where \\(P(Z &gt; z^*) = .33\\)\n\\(P(X &lt; 10)\\) where \\(X \\sim N(15, 22)\\)\n\\(P(X &gt; 40)\\) where \\(X \\sim(15,22)\\)"
  },
  {
    "objectID": "activities/12-activity.html",
    "href": "activities/12-activity.html",
    "title": "12: Bootstrap Confidence Intervals",
    "section": "",
    "text": "Part 1: StatKey\nSince we didn’t get to the StatKey activity during last class, start with completing one problem from the activity (problems assigned by group below). Once your group feels good about your answer, Groups 1-4 should add their solutions in the collaborative key google doc and Groups 5-8 are responsible for checking answers and providing alternative solutions for any discrepancies.\n\n\n\n\n\n\n\n\n\nResponsible for adding answers\nResponsible for checking answers\n\n\n\n\nProblem 1: Atlanta Commute Times\nGroup 1\nGroup 5\n\n\nProblem 2: Compassionate Rats\nGroup 2\nGroup 6\n\n\nProblem 3: Do Teen Problems Differ Based on Income Level?\nGroup 3\nGroup 7\n\n\nProblem 4: Atlanta Commute Times (again)\nGroup 4\nGroup 8\n\n\n\n\n\nPart 2: R\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(patchwork)\nlibrary(CarletonStats)\n\nThe data set Pew.csv contains part of a survey conducted by the Pew Research Center in January 2014. One of the questions they asked was, “Overall, when you add up all the advantages and disadvantages of the internet, would you say that the internet has been mostly a good thing, a bad thing, or some of both?”\nThe variable values codes the response as “good” if the respondent said the internet has been a good thing and “bad” otherwise (this includes “a bad thing” and “some of both”).\nLet’s see if this differs based on whether the respondent is 50 years or older or not.\n\nPew &lt;- read.csv(\"http://math.carleton.edu/Stat120/RLabManual/Pew.csv\")\n\nPew &lt;- Pew |&gt;\n  mutate(\n    over = ifelse(age &gt;=50, \"over50\", \"under50\"),\n    over2 = ifelse(age &gt;=50, 1, 0)\n  )\n\n1. Create an appropriate visualization of values conditioned on over. Does it appear that the proportion of over 50 year olds that said the internet has been a good thing is approximately the same as the under 50’s?\n2. Compute the exact proportions for each age group.\n3. In order to use the boot() command, the response must be coded as a binary variable of 0’s and 1’s (instead of the names of the categories). Pull up the “spreadsheet view” of the data and confirm that values and values2 contain the same information stored in a different form.\n\n\n\n\n\n\nTipMeans vs Proportions?\n\n\n\nSince the values are 0’s and 1’s, when you compute the mean, you will be computing an expression of the form\n\\[ \\frac{1 + 1 + 0 + 1 + 0 +... +0}{n}\\] which is equivalent to the proportion of 1’s. This means that we can treat proportions as means. Yay!\n\n\n4. Create a bootstrap distribution of the difference in proportions and give a sentence interpreting the 95% percentile interval. Use the variable values2, which is behavior recoded so that 1 = “good”, 0 = “bad”.\n5. Compute the 95% confidence interval based on the 95% rule. How does it compare to the percentile interval?\n\n\n\n\n\n\nNoteWhen you are done…\n\n\n\nSubmit your answers to 1-5 on a PDF on gradescope. You should submit one PDF per group and make sure that all group members who were in class are listed on the submission!"
  },
  {
    "objectID": "activities/07-activity.html",
    "href": "activities/07-activity.html",
    "title": "07: Transformations for Regression and Residual Plots",
    "section": "",
    "text": "Kathleen Vongasthorn (2007) compiled data on the top 100 films released in 2004 with the highest domestic gross over the course of its theatrical release (in US dollars). The variables in her dataset (called Movies2004.csv) are:\n\nscreens: total number of screens on which these films played in the US\nopening: total profit made during opening weekend in the US\ndomestic: total domestic gross\nworldwide: total worldwide gross\noscar: whether the film was nominated for an Academy Award\nglobe: whether the film was nominated for a Golden Globe\n\n0. Load libraries and data. Check that you can view the data and that all the variables mentioned above are there. What does each row represent?\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(patchwork)\nMovies2004 = read_csv(\"http://math.carleton.edu/Stat120/RLabManual/Movies2004.csv\")\n\n1. Create a scatterplot of worldwide against domestic. Does the relationship appear to be linear?\n2. Run the code below to perform the linear regression of worldwide against domestic. Interpret the slope and intercept in context.\n\nmovies_lm1 = lm(worldwide ~ domestic, data = Movies2004)\n\n3. Run the code below to create the residual plot with the reference line. Do you think a linear model is appropriate?\n\nmovies_aug1 = augment(movies_lm1)\nggplot(movies_aug1, aes(x = .fitted, y = .resid)) +\n  geom_point() + \n  geom_hline(yintercept = 0)\n\n\n\n\n\n\n\n\n4. Make a histogram of worldwide and domestic and describe their distribution.\n5. You should have noticed that both variables have a strong right skew. (Your answer should also include roughly where the center of the distribution is). Skew is common in variables involving money, and we often transform them using log(). The code below creates those transformed variables in Movies2004. Check the distribution of the transformed variables using a histogram. Did the transformation “lessen” the skewness?\n\nMovies2004 = Movies2004 %&gt;%\n  mutate(\n    logworld = log(worldwide),\n    logdomestic = log(domestic)\n  )\n\n6. Create a scatterplot of logworld against logdomestic. Does the relationship appear to be linear?\n7. Run the code below to create the least-squares regression of the log of worldwide gross against the log of domestic gross and call this model movies_lm2. Provide interpretations of the slope and intercept.\n\nmovies_lm2 = lm(logworld ~ logdomestic, data = Movies2004)\n\n8. Check the residual plot. Do you have any concerns about the new model?\nWhen you’re done, please knit and let Amanda know!\nNote: This activity is adapted from the Lab Manual Ch3.5. Some code differs (e.g. using _ instead of . in variable names, using mutate(), using .fitted in the residual plot) because of my personal code preference, but you can use whichever makes the most sense to you!"
  },
  {
    "objectID": "activities/23-activity.html",
    "href": "activities/23-activity.html",
    "title": "23: ANOVA in R",
    "section": "",
    "text": "When we are performing an ANOVA test for a difference in means, we can use the aov() function in R. Here is a template:\naov(y ~ x, data = dataset)\nwhere\n\ny is the column name for the response variable\nx is the column name for the categorical predictor variable\ndataset is the name of the data set"
  },
  {
    "objectID": "activities/23-activity.html#anova-in-r",
    "href": "activities/23-activity.html#anova-in-r",
    "title": "23: ANOVA in R",
    "section": "",
    "text": "When we are performing an ANOVA test for a difference in means, we can use the aov() function in R. Here is a template:\naov(y ~ x, data = dataset)\nwhere\n\ny is the column name for the response variable\nx is the column name for the categorical predictor variable\ndataset is the name of the data set"
  },
  {
    "objectID": "activities/14-activity.html",
    "href": "activities/14-activity.html",
    "title": "14: Hypothesis Tests",
    "section": "",
    "text": "Note: This is the same data that you looked at in the last in-class activity. Before starting, I recommend reviewing the question of interest and EDA that you created last time.\nThe data set Pew.csv contains part of a survey conducted by the Pew Research Center in January 2014. One of the questions they asked was, “Overall, when you add up all the advantages and disadvantages of the internet, would you say that the internet has been mostly a good thing, a bad thing, or some of both?”\nThe variable values codes the response as “good” if the respondent said the internet has been a good thing and “bad” otherwise (this includes “a bad thing” and “some of both”).\nWe want to formally test if this differs based on whether the respondent is 50 years or older or not.\n1. Write out appropriate null and alternative hypotheses.\n2. Use the permTest() command in R to test your hypotheses. (Make sure to include seed()!) You should be able to report the test statistic and p-value from the R output. Then, make a formal statistical decision and report your conclusion in context.\n3. Is this consistent with your results from last time?\n4. We could have instead stated “We want to formally test if people under 50 have a more favorable view of the internet than people over 50”. How would the null and alternative hypothesis change?\n5. The code below runs a one sided test. Talk with your group to figure out if this is the correct test for your hypotheses in (4).\n\n\n\n    ** Permutation test **\n\n Permutation test with alternative: less \n Observed statistic\n  over50 :  0.7808219    under50 :  0.8187311 \n Observed difference: -0.03791 \n\n Mean of permutation distribution: 7e-05 \n Standard error of permutation distribution: 0.03043 \n P-value:  0.1252 \n\n    *-------------*\n\n\n\n\n\n\n\n\n\nWhen you’re done, please let me know!\nIf you have time, try replicating these results with StatKey."
  },
  {
    "objectID": "activities/20-activity.html",
    "href": "activities/20-activity.html",
    "title": "20: CLT-based Confidence Intervals for Means",
    "section": "",
    "text": "(Adapted from Exercise 6.128)\n\n\nPlastic microparticles contaminate shorelines. Much of the pollution comes from washing fleece clothing. In a recent study, washing a fleece garment discharged on average \\(\\bar{X} = 290\\) fibers per liter of wastewater. The standard deviation was \\(s = 87.6\\) fibers and the sample size was \\(n=120\\).\n\n\nWhat is the estimated standard error of the average number of fibers discharged per liter of wastewater when washing a fleece garment?\nThe table below gives some percentiles of the \\(t_{119}\\) distribution. Use this information to construct a 99% confidence interval for the population mean. Interpret the interval in context.\n\n\n\n\npercentage\npercentile (qnorm(percentage))\n\n\n\n\n90%\n1.3\n\n\n95%\n1.6\n\n\n97.5%\n2.0\n\n\n99%\n2.3\n\n\n99.5%\n2.6\n\n\n\n\nWhat sample size would we need if we wanted this interval to be no wider than 20?"
  },
  {
    "objectID": "activities/05-activity.html",
    "href": "activities/05-activity.html",
    "title": "05: EDA for Quantitative Variables",
    "section": "",
    "text": "The lab manual data Pew contains data from a January 2014 Pew Research Center survey about the Internet. We’ll consider three variables from this survey:\n\nage: the person’s age, in years\nincome: the person’s yearly income, grouped into four categories\nvalues: an answer to the question asking if the Internet has been a “good thing”\n\n-1. Run the code chunk below to load the libraries we need for this activity.\n\nlibrary(tidyverse)\n\n0. Import the data into R by running the following code chunk. This chunk also includes a line to redefine the levels of the income variable so that they show up in the right order. Click on the dataset in the environment pane to pull up the data viewer. Can you see the “spreadsheet view” of the data?\n\npew &lt;- read_csv(\"http://www.math.carleton.edu/Stat120/RLabManual/Pew.csv\")\npew$income &lt;- factor(pew$income, levels = c(\"0-30000\", \"30000-75000\",\n                                            \"75000-150000\", \"150000\"))\n\n1. If you haven’t already, create a histogram of the age variable using esquisse. Make sure to copy your code to the chunk below.\n2. In the empty code chunk below, run mean(pew$age) and median(pew$age). Now try mode(pew$age). What happened?\n3. Compute the standard deviation of age. Does the 68/95/99 rule apply? Find the interval where 95% of the cases should fall.\n4. Let’s see if you’re right! The chunk of code below filters the data to only include values where age is greater or equal to 18 and less than or equal to 99 and then spits out how many cases are in the filtered dataset. These are the minimum and maximum values, so the entire dataset is included. Edit this chunk so it corresponds to your interval values above. How close to 95% is it?\n\npew %&gt;%\n  filter(age &lt;= 99 & age &gt;= 18) %&gt;%\n  summarize(\n    n = n()\n  )\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   696\n\n\n4. Are people who think the internet has been a “good thing” younger than those that don’t? Create side-by-side boxplots to answer the question. (You can use ggplot, base R, or esquisse to create your boxplots)\n5. Another way to look at the distribution of a quantitative variable across different levels of a categorical variable is using facets. Facets create a different graph for each level of a categorical variable. Choose one method below. + In esquisse, create a histogram of age and then drag values into the facet box (far right) + If using ggplot directly, create a histogram of age and then add facet_wrap(vars(values)) What can you see using the histogram approach that you cannot see with the side-by-side boxplots?\n6. We also often want summary statistics per group. The code below groups the data by values, and then computes the mean and median for each group. Add a line of code to compute the sd() for each group. (You may also need to add a comma at the end of a line) Do these quantities align with the visualizations that you made above?\n\npew %&gt;%\n  group_by(values) %&gt;%\n  summarize(\n    mean_age = mean(age), \n    median_age = median(age)\n  )\n\n# A tibble: 2 × 3\n  values mean_age median_age\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 bad        49.0         51\n2 good       48.2         50\n\n\nStop here. and let Amanda know that you’ve finished with the pew data portion.\n\nPart 2: Outliers and Log Transformations\nFor the part of the activity, we’re going to be looking at the CEO salaries for S&P 500 companies. This data was gathered by AFL-CIO and more information about the data is available on their website.\n0. Import the data into R by running the following code chunk. Click on the dataset in the environment pane to pull up the data viewer. Can you see the “spreadsheet view” of the data? List the variables and whether they are categorical or quantitative. Note any ID variables.\n\nceo_salaries = read_csv(\"https://math.carleton.edu/aluby/data/ceo_salaries_23_24.csv\")\n\n1. Using esquisse, ggplot, or base R, create a histogram of the Pay variable\n2. Compute the mean,median, and sd of the Pay variable and describe the distribution. (You should focus on the shape, center, and spread.).\n3. You should have noted that the distribution is right-skewed (it has a long right tail). The code below demonstrates one way to remove outliers by filtering the very large observations and saving it to a new dataset called ceo_salaries_outliers. Run the code below, and then view the new dataset. Which companies have the highest CEO pay?\n\nceo_salaries_outliers &lt;- ceo_salaries %&gt;%\n  filter(Pay &gt; 100000000) \n\n4. Next, create a dataset called ceo_salaries_filtered that includes all cases where Pay is less than $100,000,000. Create a histogram of the Pay variable for this filtered dataset and compute the mean and median.\n5. Alternatively, we can visualize and work with a transformation of our dataset. This is especially useful when we have a “long-tailed” dataset. Explain what the next few lines of code do.\n\nceo_salaries = ceo_salaries %&gt;%\n  mutate(log_pay = log(Pay + 1))\n\nceo_salaries %&gt;%\n  summarize(mean = mean(log_pay),\n            median = median(log_pay))\n\n# A tibble: 1 × 2\n   mean median\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  16.4   16.6\n\n\n6. Create a histogram of the log_pay variable and describe the shape of the distribution.\n7. Your answer to 6 should note that there’s now low outlier(s)! Find these outlier(s). Which companies are they? What do they pay their CEOs? (Note: you should do this using code, but can check your answer with the “spreadsheet view” of the data.)\nWhen you’re done, please knit and save your file."
  },
  {
    "objectID": "activities/21-activity.html",
    "href": "activities/21-activity.html",
    "title": "21.1: CLT-based Inference for Difference in Proportions",
    "section": "",
    "text": "APM Research Lab ran a survey of 800 likely Minnesota voters between Sept 16-18 of this year. They reported 48.4% were in support of the Harris/Walz ticket, and 43.3% were in support of the Trump/Vance ticket.\nHere’s an excerpt from their methodology report:\n\nThe margin for error, according to standards customarily used by statisticians, is no more than ± 3.5 percentage points. The margin of error is approximately 7 percentage points for the difference between two data points…. The margin of error is higher for any subgroup, such as gender or age grouping.\n\n\nWhat is the standard error for the difference in proportions?\n\n\nExplain why we should not use the CLT formula for the difference in proportions between Harris supporters and Trump supporters in this poll\n\n\nInstead, we’ll look at the difference in suppport for Harris between two different levels of education. (We can assume that the poll included 436 in the “no college degree” group and 360 in the “college degree” group). Show two ways that the standard error could have been computed.\n\n\n\n\n\n\n\n\n\n\n\nThe two ways of computing the standard error should produce similar results. Give two reasons why.\n\n\nThe following R code makes a confidence interval and performs a hypothesis test for the difference in these two proportions.\n\n\nWhere did x = c(192, 194) come from?\n\n\n\nWhat is \\(\\alpha\\) for the hypothesis test?\n\n\n\nProvide an in-context interpretation of the confidence interval (it should be clear in your answer which group had more support for Harris)\n\n\n\nprop.test(x = c(192, 194), \n          n = c(436, 360),\n          correct = FALSE, #tells R not to apply a \"continuity correction\"\n          conf.level = .90)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(192, 194) out of c(436, 360)\nX-squared = 7.663, df = 1, p-value = 0.005637\nalternative hypothesis: two.sided\n90 percent confidence interval:\n -0.15680365 -0.04024018\nsample estimates:\n   prop 1    prop 2 \n0.4403670 0.5388889 \n\n\n\nWhat concept or topic is your group most confused about? (Some ideas to get you started: qnorm vs pnorm, normal vs t distribution, choosing a parameter, standard error formulas, when to use confidence intervals vs hypothesis tests)"
  },
  {
    "objectID": "activities/10-activity.html",
    "href": "activities/10-activity.html",
    "title": "10: Sampling Distributions with StatKey",
    "section": "",
    "text": "No R needed today! We’ll focus on concepts and intuition with StatKey\n\n\n\n1.  Use StatKey’s mean menu: https://www.lock5stat.com/StatKey/sampling_1_quant/sampling_1_quant.html and select “Percent with internet access 3e (countries)”. Click “Show data table”.\n\nWhat is each case?\nWhat is each variable?\nDo you think this dataset represents a population or a sample?\nClose the dataset viewer. Click “Generate 10 samples”. What does each dot represent?\nWhat happens to the shape, center, and spread of the sampling distribution as n increases? (You can use “Generate 1000 samples” to speed this up)\nIs there a number of samples where the distribution doesn’t change much?\n\n2. Use StatKey’s proportion menu: https://www.lock5stat.com/StatKey/sampling_1_cat/sampling_1_cat.html to answer the following. (a) Click the “edit proportion” button to change the population parameter p\n\nChoose a value of p that is between .2 and .8. Describe how the shape, center, and spread of the sampling distribution changes as n increases\nDescribe how the shape, center, and spread of the sampling distribution changes as p gets closer to 1\n\n3. About 10% of the worldwide population is left-handed. A 200-seat lecture hall has been built with 15 rows (the number of seats in each row varies). Each row has a single “lefty seat” that has the built-in desk on the left rather than the right arm of the chair. In a class of 90 students, what’s the probability that there will not be enough seats for the left-handed students?\n\nWhat number of left-handed students would have to be in the class for there to not be enough desks?\nSet up the sampling distribution using StatKey. What is p and n?\nSimulate 1000 samples. Use the results to estimate the probability.\nNow suppose there’s a class of 50 instead. Do you think this probability will be higher, lower, or about the same as (d)?\nUse StatKey to estimate the probability in (d). Are you surprised?\n\n4. Explain the difference between (1) the distribution of a population, (2) the distribution of a sample, (3) the sampling distribution. Be sure to fill in these definitions in your note sheet.\nWhen you’re done, submit the answers to number 3 on gradescope. You only need to submit 1 per group."
  },
  {
    "objectID": "slides/test.html#first-slide",
    "href": "slides/test.html#first-slide",
    "title": "My Test Slides",
    "section": "First Slide",
    "text": "First Slide\nThis is a test slide. This is a test link"
  },
  {
    "objectID": "slides/test.html#second-slide",
    "href": "slides/test.html#second-slide",
    "title": "My Test Slides",
    "section": "Second Slide",
    "text": "Second Slide\nIf this works, the problem is in the YAML of the other .qmd file."
  },
  {
    "objectID": "slides/04-slides.html#today",
    "href": "slides/04-slides.html#today",
    "title": "04: EDA for Categorical Variables",
    "section": "Today:",
    "text": "Today:\n\nEDA for 1 Categorical Variable\nEDA for 2 Categorical Variables\nPractice in R"
  },
  {
    "objectID": "slides/04-slides.html#load-data",
    "href": "slides/04-slides.html#load-data",
    "title": "04: EDA for Categorical Variables",
    "section": "Load Data",
    "text": "Load Data\n\npenguins = palmerpenguins::penguins\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/04-slides.html#species",
    "href": "slides/04-slides.html#species",
    "title": "04: EDA for Categorical Variables",
    "section": "species",
    "text": "species\nCategorical variables are best summarized with a frequency table and visualized with a barplot. When we want to summarize a categorical variable with a single number, we often use a proportion\n\n\n\nProportion (or percentage)\n\n\n\\[\\hat{p} = \\frac{\\text{The number within a category}}{\\text{Total number}}\\]\nWe use \\(p\\) if this denotes a population proportion, or \\(\\hat{p}\\) if it denotes a sample proportion"
  },
  {
    "objectID": "slides/04-slides.html#frequency-table",
    "href": "slides/04-slides.html#frequency-table",
    "title": "04: EDA for Categorical Variables",
    "section": "Frequency Table",
    "text": "Frequency Table\n\ntable(penguins$species)\n\n\n   Adelie Chinstrap    Gentoo \n      152        68       124"
  },
  {
    "objectID": "slides/04-slides.html#barplot",
    "href": "slides/04-slides.html#barplot",
    "title": "04: EDA for Categorical Variables",
    "section": "Barplot",
    "text": "Barplot\n\nggplot(penguins, aes(x = species)) + \n  geom_bar()"
  },
  {
    "objectID": "slides/04-slides.html#barplot-y-axis",
    "href": "slides/04-slides.html#barplot-y-axis",
    "title": "04: EDA for Categorical Variables",
    "section": "Barplot: y-axis",
    "text": "Barplot: y-axis\n\nggplot(penguins, aes(y = species)) + \n  geom_bar()"
  },
  {
    "objectID": "slides/04-slides.html#barplot-with-color",
    "href": "slides/04-slides.html#barplot-with-color",
    "title": "04: EDA for Categorical Variables",
    "section": "Barplot: with color!",
    "text": "Barplot: with color!\n\nggplot(penguins, aes(y = species, fill = species)) + \n  geom_bar()"
  },
  {
    "objectID": "slides/04-slides.html#relationship-between-species-and-island",
    "href": "slides/04-slides.html#relationship-between-species-and-island",
    "title": "04: EDA for Categorical Variables",
    "section": "Relationship between species and island",
    "text": "Relationship between species and island\n\ntable(penguins$species, penguins$island)\n\n           \n            Biscoe Dream Torgersen\n  Adelie        44    56        52\n  Chinstrap      0    68         0\n  Gentoo       124     0         0\n\n\n\n\nHow would you represent this information using a barplot?"
  },
  {
    "objectID": "slides/04-slides.html#relationship-between-species-and-island-1",
    "href": "slides/04-slides.html#relationship-between-species-and-island-1",
    "title": "04: EDA for Categorical Variables",
    "section": "Relationship between species and island",
    "text": "Relationship between species and island\n\nggplot(penguins, aes(y = species, fill = island)) + \n  geom_bar()"
  },
  {
    "objectID": "slides/04-slides.html#joint-distribution",
    "href": "slides/04-slides.html#joint-distribution",
    "title": "04: EDA for Categorical Variables",
    "section": "Joint “Distribution”",
    "text": "Joint “Distribution”\nDistribution = proportions\n\ntable(penguins$species, penguins$island) %&gt;%\n  proportions() \n\n           \n               Biscoe     Dream Torgersen\n  Adelie    0.1279070 0.1627907 0.1511628\n  Chinstrap 0.0000000 0.1976744 0.0000000\n  Gentoo    0.3604651 0.0000000 0.0000000"
  },
  {
    "objectID": "slides/04-slides.html#conditional-distribution",
    "href": "slides/04-slides.html#conditional-distribution",
    "title": "04: EDA for Categorical Variables",
    "section": "Conditional Distribution",
    "text": "Conditional Distribution\nConditional distribution of species on Dream island\n\ntable(penguins$species, penguins$island) \n\n           \n            Biscoe Dream Torgersen\n  Adelie        44    56        52\n  Chinstrap      0    68         0\n  Gentoo       124     0         0\n\n\n\n\ntable(penguins$species, penguins$island) %&gt;%\n  proportions(2) # condition on COLUMNS\n\n           \n               Biscoe     Dream Torgersen\n  Adelie    0.2619048 0.4516129 1.0000000\n  Chinstrap 0.0000000 0.5483871 0.0000000\n  Gentoo    0.7380952 0.0000000 0.0000000"
  },
  {
    "objectID": "slides/04-slides.html#marginal-distribution",
    "href": "slides/04-slides.html#marginal-distribution",
    "title": "04: EDA for Categorical Variables",
    "section": "Marginal Distribution",
    "text": "Marginal Distribution\nMarginal distribution of species\n\ntable(penguins$species, penguins$island) %&gt;%\n  addmargins()\n\n           \n            Biscoe Dream Torgersen Sum\n  Adelie        44    56        52 152\n  Chinstrap      0    68         0  68\n  Gentoo       124     0         0 124\n  Sum          168   124        52 344\n\n\n\n\ntable(penguins$species) %&gt;%\n  proportions()\n\n\n   Adelie Chinstrap    Gentoo \n0.4418605 0.1976744 0.3604651"
  },
  {
    "objectID": "slides/07-slides.html#today",
    "href": "slides/07-slides.html#today",
    "title": "07: Linear Regression",
    "section": "Today:",
    "text": "Today:\n\nMore on linear regression\nMore on transformations\nAnother R activity"
  },
  {
    "objectID": "slides/07-slides.html#fitting-the-least-squares-line",
    "href": "slides/07-slides.html#fitting-the-least-squares-line",
    "title": "07: Linear Regression",
    "section": "Fitting the least squares line",
    "text": "Fitting the least squares line\n\n\n\nCall:\nlm(formula = flipper_length_mm ~ body_mass_g, data = penguins)\n\nCoefficients:\n(Intercept)  body_mass_g  \n  136.72956      0.01528  \n\n\n\nIntercept (\\(b_0\\)): where does the line cross the y-axis? What is the prediction for \\(x=0\\)?\nSlope (\\(b_1\\)): For a 1-unit increase in \\(x\\), what is the change in the prediction for \\(y\\)?"
  },
  {
    "objectID": "slides/07-slides.html#important-notation",
    "href": "slides/07-slides.html#important-notation",
    "title": "07: Linear Regression",
    "section": "Important Notation",
    "text": "Important Notation\nObservations (\\(y_i\\)): the data points that were observed"
  },
  {
    "objectID": "slides/07-slides.html#important-notation-1",
    "href": "slides/07-slides.html#important-notation-1",
    "title": "07: Linear Regression",
    "section": "Important Notation",
    "text": "Important Notation\nPredictions (\\(\\hat{y}_i\\)): the points on the line for each \\(x\\) value\n\\[\\hat{y}_i = b_0 + b_1 x_i\\]"
  },
  {
    "objectID": "slides/07-slides.html#important-notation-2",
    "href": "slides/07-slides.html#important-notation-2",
    "title": "07: Linear Regression",
    "section": "Important Notation",
    "text": "Important Notation\nResiduals (\\(\\epsilon_i\\)): difference between observations and predictions\n\\[\\epsilon_i = y_i - \\hat{y}_i  \\]"
  },
  {
    "objectID": "slides/07-slides.html#example",
    "href": "slides/07-slides.html#example",
    "title": "07: Linear Regression",
    "section": "Example",
    "text": "Example\nRecall the least squares equation in this case was \\[\n\\operatorname{\\widehat{flipper\\_length\\_mm}} = 136.73 + 0.015(\\operatorname{body\\_mass\\_g})\n\\]\nI grab a penguin with a flipper length of 193mm and a body mass of 3475g. What is the observation, prediction, and residual in this case?"
  },
  {
    "objectID": "slides/07-slides.html#the-penguin_dives-dataset.",
    "href": "slides/07-slides.html#the-penguin_dives-dataset.",
    "title": "07: Linear Regression",
    "section": "The penguin_dives dataset.",
    "text": "The penguin_dives dataset.\nEmperor penguins routinely make dives of 5-12 minutes, with the longest recorded dive over 27 minutes (!!) The rate of oxygen depletion is primarily determined by the penguin’s heart rate. Consequently, studies of heart rates during dives can help us understand how these animals regulate their oxygen consumption in order to make such impressive dives."
  },
  {
    "objectID": "slides/07-slides.html#data",
    "href": "slides/07-slides.html#data",
    "title": "07: Linear Regression",
    "section": "Data",
    "text": "Data\nDiveHeartRate is the bird’s heart rate in beats per minute, Depth is the depth of the dive (in meters), Duration is the duration of the dive in minutes, and Bird is an ID variable indicating which penguin made the dive.\n\n\n# A tibble: 125 × 4\n   DiveHeartRate Depth Duration Bird \n           &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;\n 1          88.8   5       1.05 EP19 \n 2         103.    9       1.18 EP19 \n 3          97.4  22       1.92 EP19 \n 4          85.3  25.5     3.47 EP19 \n 5          60.6  30.5     7.08 EP19 \n 6          77.6  32.5     4.77 EP19 \n 7          44.3  38       9.13 EP19 \n 8          32.8  32      11    EP19 \n 9          94.2   6       1.32 EP19 \n10          99.8  10.5     1.48 EP19 \n# ℹ 115 more rows"
  },
  {
    "objectID": "slides/07-slides.html#is-it-linear",
    "href": "slides/07-slides.html#is-it-linear",
    "title": "07: Linear Regression",
    "section": "Is it linear?",
    "text": "Is it linear?\n\nggplot(penguin_dives, aes(x = Duration, y = DiveHeartRate)) + \n  geom_point() + \n  stat_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#is-it-linear-1",
    "href": "slides/07-slides.html#is-it-linear-1",
    "title": "07: Linear Regression",
    "section": "Is it linear?",
    "text": "Is it linear?\n\nggplot(penguin_dives, aes(x = Duration, y = DiveHeartRate)) + \n  geom_point() + \n  stat_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#residual-scatterplot",
    "href": "slides/07-slides.html#residual-scatterplot",
    "title": "07: Linear Regression",
    "section": "Residual scatterplot",
    "text": "Residual scatterplot"
  },
  {
    "objectID": "slides/07-slides.html#it-can-be-easier-to-see-curvature-with-a-horizontal-reference-line",
    "href": "slides/07-slides.html#it-can-be-easier-to-see-curvature-with-a-horizontal-reference-line",
    "title": "07: Linear Regression",
    "section": "It can be easier to see curvature with a horizontal reference line",
    "text": "It can be easier to see curvature with a horizontal reference line"
  },
  {
    "objectID": "slides/07-slides.html#and-sometimes-we-put-predictions-on-the-x-axis-instead",
    "href": "slides/07-slides.html#and-sometimes-we-put-predictions-on-the-x-axis-instead",
    "title": "07: Linear Regression",
    "section": "And sometimes we put predictions on the x-axis instead",
    "text": "And sometimes we put predictions on the x-axis instead\n\nTo make sure that we’re working with a linear relationship, it’s best practice to make a residual plot alongside the X-Y scatterplot when checking for curvature."
  },
  {
    "objectID": "slides/07-slides.html#to-make-a-residual-scatterplot",
    "href": "slides/07-slides.html#to-make-a-residual-scatterplot",
    "title": "07: Linear Regression",
    "section": "To make a residual scatterplot",
    "text": "To make a residual scatterplot\nStep 1: Fit model and save it to an object\n\ndives_lm = lm(DiveHeartRate ~ Duration, data = penguin_dives)"
  },
  {
    "objectID": "slides/07-slides.html#to-make-a-residual-scatterplot-1",
    "href": "slides/07-slides.html#to-make-a-residual-scatterplot-1",
    "title": "07: Linear Regression",
    "section": "To make a residual scatterplot",
    "text": "To make a residual scatterplot\nStep 2: Create augmented dataset. This creates a dataset which contains the original response and explanatory variables, a column with the residuals (.resid), a column with the predictions (.fitted), along with other quantities you’ll see in future stats courses. augment() lives in the broom library, which we need to remember to load.\n\nlibrary(broom)\ndives_aug = augment(dives_lm)\ndives_aug\n\n# A tibble: 125 × 8\n   DiveHeartRate Duration .fitted .resid    .hat .sigma  .cooksd .std.resid\n           &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1          88.8     1.05    91.2  -2.36 0.0270    14.2 0.000400     -0.170\n 2         103.      1.18    90.4  13.0  0.0262    14.1 0.0117        0.931\n 3          97.4     1.92    86.4  11.0  0.0221    14.1 0.00700       0.787\n 4          85.3     3.47    77.9   7.35 0.0152    14.2 0.00212       0.525\n 5          60.6     7.08    58.2   2.43 0.00803   14.2 0.000121      0.173\n 6          77.6     4.77    70.8   6.76 0.0111    14.2 0.00131       0.482\n 7          44.3     9.13    47.0  -2.66 0.00961   14.2 0.000174     -0.189\n 8          32.8    11       36.8  -3.95 0.0146    14.2 0.000590     -0.282\n 9          94.2     1.32    89.7   4.50 0.0255    14.2 0.00136       0.323\n10          99.8     1.48    88.8  11.0  0.0245    14.1 0.00783       0.790\n# ℹ 115 more rows"
  },
  {
    "objectID": "slides/07-slides.html#to-make-a-residual-scatterplot-2",
    "href": "slides/07-slides.html#to-make-a-residual-scatterplot-2",
    "title": "07: Linear Regression",
    "section": "To make a residual scatterplot",
    "text": "To make a residual scatterplot\nStep 3. Create the scatterplot using the augmented dataset\n\nggplot(dives_aug, aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept =0)"
  },
  {
    "objectID": "slides/07-slides.html#what-do-we-ideally-want-to-see",
    "href": "slides/07-slides.html#what-do-we-ideally-want-to-see",
    "title": "07: Linear Regression",
    "section": "What do we ideally want to see?",
    "text": "What do we ideally want to see?"
  },
  {
    "objectID": "slides/07-slides.html#reasons-we-do-transformations",
    "href": "slides/07-slides.html#reasons-we-do-transformations",
    "title": "07: Linear Regression",
    "section": "Reasons we do transformations",
    "text": "Reasons we do transformations\n\nMake the distribution (i.e. histogram) of a variable more symmetric\n\nEasier to summarize (mean \\(\\approx\\) median)\nCan use 68/95/99 rule\n\nMake the spread of different groups (i.e. boxplot) more alike, even if their centers differ\n\nWe’ll get to why this is important later in the course\n\nMake the form of a scatterplot closer to a linear relationship\n\nSo we can trust the results from the linear regression line and correlation"
  },
  {
    "objectID": "slides/07-slides.html#check-distributions-of-each-variable",
    "href": "slides/07-slides.html#check-distributions-of-each-variable",
    "title": "07: Linear Regression",
    "section": "Check distributions of each variable",
    "text": "Check distributions of each variable\n\np1 = ggplot(penguin_dives, aes(x = Duration)) + \n  geom_histogram(col = \"white\", bins  =20)\n\np2 = ggplot(penguin_dives, aes(x = DiveHeartRate)) + \n  geom_histogram(col = \"white\", bins = 20)\n\np1 + p2\n\n\n\nIf you notice lots of skew, start by transforming that variable"
  },
  {
    "objectID": "slides/07-slides.html#transforming-the-y-variable",
    "href": "slides/07-slides.html#transforming-the-y-variable",
    "title": "07: Linear Regression",
    "section": "Transforming the y-variable",
    "text": "Transforming the y-variable"
  },
  {
    "objectID": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot",
    "href": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot",
    "title": "07: Linear Regression",
    "section": "Checking the transformed X-Y scatterplot",
    "text": "Checking the transformed X-Y scatterplot\n\nggplot(penguin_dives, aes(x = Duration, y = DiveHeartRate^2)) + \n  geom_point() + \n  stat_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-1",
    "href": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-1",
    "title": "07: Linear Regression",
    "section": "Checking the transformed X-Y scatterplot",
    "text": "Checking the transformed X-Y scatterplot\n\nggplot(penguin_dives, aes(x = Duration, y = sqrt(DiveHeartRate))) + \n  geom_point() + \n  stat_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-2",
    "href": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-2",
    "title": "07: Linear Regression",
    "section": "Checking the transformed X-Y scatterplot",
    "text": "Checking the transformed X-Y scatterplot\n\nggplot(penguin_dives, aes(x = Duration, y = log(DiveHeartRate))) + \n  geom_point() + \n  stat_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-3",
    "href": "slides/07-slides.html#checking-the-transformed-x-y-scatterplot-3",
    "title": "07: Linear Regression",
    "section": "Checking the transformed X-Y scatterplot",
    "text": "Checking the transformed X-Y scatterplot\n\nggplot(penguin_dives, aes(x = Duration, y = -1/DiveHeartRate)) + \n  geom_point() + \n  stat_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/07-slides.html#fitting-the-transformed-model",
    "href": "slides/07-slides.html#fitting-the-transformed-model",
    "title": "07: Linear Regression",
    "section": "Fitting the transformed model",
    "text": "Fitting the transformed model\n\nAdd new column to dataset\n\npenguin_dives = penguin_dives %&gt;%\n  mutate(\n    recip_DHR = -1/DiveHeartRate\n  )\n\n\n\nFit model and print output\n\ndives_lm2 = lm(recip_DHR ~ Duration, data = penguin_dives)\ndives_lm2\n\n\nCall:\nlm(formula = recip_DHR ~ Duration, data = penguin_dives)\n\nCoefficients:\n(Intercept)     Duration  \n  -0.007926    -0.001817"
  },
  {
    "objectID": "slides/07-slides.html#example-1",
    "href": "slides/07-slides.html#example-1",
    "title": "07: Linear Regression",
    "section": "Example",
    "text": "Example\nBelow is the slope and intercept for the transformed model. Write out the linear regression equation and provide an in-context interpretation of the intercept and slope\n\n\n\nCall:\nlm(formula = recip_DHR ~ Duration, data = penguin_dives)\n\nCoefficients:\n(Intercept)     Duration  \n  -0.007926    -0.001817  \n\n\n\nFor a dive with duration 0, we expect the average reciprocal of DiveHeartRate to be -.0079\nFor every 1-minute increase in dive Duration, we expect the average reciprocal of DiveHeartRate to be .0018 BPM lower."
  },
  {
    "objectID": "slides/07-slides.html#residual-plot-again",
    "href": "slides/07-slides.html#residual-plot-again",
    "title": "07: Linear Regression",
    "section": "Residual Plot (again)",
    "text": "Residual Plot (again)\nIt’s also best practice to make the new residual plot\n\ndives_aug2 = augment(dives_lm2)\nggplot(dives_aug2, aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept =0)\n\n\nSince it looks more “like a cloud” without clear curvature, we should be safe to use our linear regression model for predictions."
  },
  {
    "objectID": "slides/07-slides.html#summary",
    "href": "slides/07-slides.html#summary",
    "title": "07: Linear Regression",
    "section": "Summary",
    "text": "Summary\n\nLinear regression is a powerful tool to explain the average relationship between 2 quantitative variables\nIt’s important for the relationship to be roughly linear\nIf it’s not linear, we can try transforming \\(Y\\) and/or \\(X\\) (but need to be careful about interpretation!)\nThere’s not one true correct transformation and you shouldn’t spend a bunch of time trying to find one\nBut there are lots of wrong ones!\nProvide justification for your choice and point out potential weaknesses"
  },
  {
    "objectID": "slides/10-midterm-checkin.html#a-note-on-regrade-requests",
    "href": "slides/10-midterm-checkin.html#a-note-on-regrade-requests",
    "title": "Midterm 1 + Check-in",
    "section": "A note on regrade requests:",
    "text": "A note on regrade requests:\n\nGrading is often a tedious task, and the grading team will sometimes make mistakes. I am always happy to fix these mistakes, and gradescope makes it easy to do so.\nRegrade requests must be submitted on gradescope within two weekdays after homework has been returned to you.\nRegrade requests are for administrative errors or obvious grading mistakes. I will not consider regrade requests for anything that applied to the entire class (e.g. “I think this mistake should only be worth 1 point instead of 2” or “I didn’t realize we had to do X”).\nIf you submit two or more inappropriate regrade requests, I will not consider additional regrade requests from you for the remainder of the term.\nIf you’re unsure whether you should file a regrade request or not, just ask! You are always welcome to discuss any grading questions with me in office hours."
  },
  {
    "objectID": "slides/10-midterm-checkin.html#section",
    "href": "slides/10-midterm-checkin.html#section",
    "title": "Midterm 1 + Check-in",
    "section": "",
    "text": "Going Well\n\nPrep before class (readings, video, pre-class assignment)\nNote Sheets are helpful\nGroup work\nHomework\nManageable workload\nPace is good\nR is fun/not that bad/etc.\n\n\nThings to change:\n\nR: more code examples on handouts\nR: explain more step by step\nSome homework questions are hard to figure out what its asking for"
  },
  {
    "objectID": "slides/10-midterm-checkin.html#balance-of-lecturesgroup-work",
    "href": "slides/10-midterm-checkin.html#balance-of-lecturesgroup-work",
    "title": "Midterm 1 + Check-in",
    "section": "Balance of lectures/group work",
    "text": "Balance of lectures/group work"
  },
  {
    "objectID": "slides/10-midterm-checkin.html#pre-class-videos",
    "href": "slides/10-midterm-checkin.html#pre-class-videos",
    "title": "Midterm 1 + Check-in",
    "section": "Pre-class videos",
    "text": "Pre-class videos"
  },
  {
    "objectID": "slides/10-midterm-checkin.html#how-helpful-is.",
    "href": "slides/10-midterm-checkin.html#how-helpful-is.",
    "title": "Midterm 1 + Check-in",
    "section": "How helpful is….",
    "text": "How helpful is…."
  },
  {
    "objectID": "slides/10-midterm-checkin.html#how-much-timehow-often",
    "href": "slides/10-midterm-checkin.html#how-much-timehow-often",
    "title": "Midterm 1 + Check-in",
    "section": "How much time/How often",
    "text": "How much time/How often"
  },
  {
    "objectID": "slides/10-midterm-checkin.html#my-goals-for-the-rest-of-term",
    "href": "slides/10-midterm-checkin.html#my-goals-for-the-rest-of-term",
    "title": "Midterm 1 + Check-in",
    "section": "My goals for the rest of term:",
    "text": "My goals for the rest of term:\n\nMore R code on handouts\nContinue mixing in videos for class prep"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "stat120",
    "section": "",
    "text": "You’ve found the landing page for Amanda Luby’s Stat120 course materials\n\n\n\n\n\n\nImportantCaution\n\n\n\nMaterial found here (instead of moodle) may be out of date"
  },
  {
    "objectID": "slides/08-slides.html#today",
    "href": "slides/08-slides.html#today",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Today:",
    "text": "Today:\n\n15-20 minutes to wrap up activity from last class\nCustomizing ggplots\nExam Review"
  },
  {
    "objectID": "slides/08-slides.html#choice-of-graphical-form-1",
    "href": "slides/08-slides.html#choice-of-graphical-form-1",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Choice of graphical form",
    "text": "Choice of graphical form"
  },
  {
    "objectID": "slides/08-slides.html#choice-of-graphical-form-2",
    "href": "slides/08-slides.html#choice-of-graphical-form-2",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Choice of graphical form",
    "text": "Choice of graphical form"
  },
  {
    "objectID": "slides/08-slides.html#distorting-the-y-axis",
    "href": "slides/08-slides.html#distorting-the-y-axis",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Distorting the y-axis",
    "text": "Distorting the y-axis"
  },
  {
    "objectID": "slides/08-slides.html#distorting-the-y-axis-1",
    "href": "slides/08-slides.html#distorting-the-y-axis-1",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Distorting the y-axis",
    "text": "Distorting the y-axis\n\nggplot(penguins, aes(x = body_mass_g, y= flipper_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  ylim(c(0, 250))"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization",
    "href": "slides/08-slides.html#other-ggplot-customization",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter() + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-1",
    "href": "slides/08-slides.html#other-ggplot-customization-1",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5)"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-2",
    "href": "slides/08-slides.html#other-ggplot-customization-2",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5)"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-3",
    "href": "slides/08-slides.html#other-ggplot-customization-3",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_bw()"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-4",
    "href": "slides/08-slides.html#other-ggplot-customization-4",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-5",
    "href": "slides/08-slides.html#other-ggplot-customization-5",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_brewer(palette = \"Greens\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-6",
    "href": "slides/08-slides.html#other-ggplot-customization-6",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_brewer(palette = \"Spectral\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-7",
    "href": "slides/08-slides.html#other-ggplot-customization-7",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-8",
    "href": "slides/08-slides.html#other-ggplot-customization-8",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_viridis_d(option =\"plasma\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-9",
    "href": "slides/08-slides.html#other-ggplot-customization-9",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_viridis_d(option =\"plasma\") + \n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-10",
    "href": "slides/08-slides.html#other-ggplot-customization-10",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal() + \n  scale_fill_viridis_d(option =\"plasma\") + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-11",
    "href": "slides/08-slides.html#other-ggplot-customization-11",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal(base_size = 20) + \n  scale_fill_viridis_d(option =\"plasma\") + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/08-slides.html#other-ggplot-customization-12",
    "href": "slides/08-slides.html#other-ggplot-customization-12",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "Other ggplot customization",
    "text": "Other ggplot customization\n\nggplot(penguins, aes(x = species, y = flipper_length_mm, fill = species)) + \n  geom_jitter(alpha = .2) + \n  geom_boxplot(alpha = .5) +\n  theme_minimal(base_size = 20) + \n  scale_fill_viridis_d(option =\"plasma\") + \n  theme(legend.position = \"none\") + \n  labs(\n    title = \"Gentoo Penguins have the longest flipper lengths\",\n    subtitle = \"Adelie and Chinstrap Penguins are smaller\",\n    y = \"Flipper Length (mm)\",\n    x = \"\",\n    caption = \"Source: PalmerPenguins\"\n  )"
  },
  {
    "objectID": "slides/08-slides.html#in-esquisse",
    "href": "slides/08-slides.html#in-esquisse",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "In esquisse",
    "text": "In esquisse\nChange theme under the “theme” menu:"
  },
  {
    "objectID": "slides/08-slides.html#in-esquisse-1",
    "href": "slides/08-slides.html#in-esquisse-1",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "In esquisse",
    "text": "In esquisse\nChange color palette under the “geometries” menu:"
  },
  {
    "objectID": "slides/08-slides.html#in-esquisse-2",
    "href": "slides/08-slides.html#in-esquisse-2",
    "title": "08: Customizing GGplots + Exam 1 Review",
    "section": "In esquisse",
    "text": "In esquisse\nChange title and axis labels under the “labels and title” menu:"
  },
  {
    "objectID": "slides/01-welcome-slides.html#plan-for-today",
    "href": "slides/01-welcome-slides.html#plan-for-today",
    "title": "Welcome to Stat120!",
    "section": "Plan for today",
    "text": "Plan for today\n\nIntros\nSyllabus/About the Course\nIntro to Data"
  },
  {
    "objectID": "slides/01-welcome-slides.html#about-me",
    "href": "slides/01-welcome-slides.html#about-me",
    "title": "Welcome to Stat120!",
    "section": "About me",
    "text": "About me\n\n\n\nEllis (almost 1.5!)\nSecond year at Carleton\nTaught at Swarthmore for 5 years before moving to MN\nPhD in Statistics & Data Science from Carnegie Mellon University\nGrew up in Minnesota, went to St Ben’s as an undergrad"
  },
  {
    "objectID": "slides/01-welcome-slides.html#my-crochet-journey-this-summer",
    "href": "slides/01-welcome-slides.html#my-crochet-journey-this-summer",
    "title": "Welcome to Stat120!",
    "section": "My crochet journey this summer",
    "text": "My crochet journey this summer\n\n\n\n\n\nDecided I wanted to make a basket\nSkipped “practice these stitches” and just went for it\nDidn’t understand the pattern, watched a couple of youtube videos from random creators and went for it\nKept going even when I was very clearly doing something wrong"
  },
  {
    "objectID": "slides/01-welcome-slides.html#my-crochet-journey-this-summer-1",
    "href": "slides/01-welcome-slides.html#my-crochet-journey-this-summer-1",
    "title": "Welcome to Stat120!",
    "section": "My crochet journey this summer",
    "text": "My crochet journey this summer\n\n\n\n\n\nAsked an expert (my sister) for advice\nDid “practice problems” using easier material (yarn) and bigger hook\nFound a reliable internet source for videos and tutorials\nStarted being way more careful about checking my work and redoing things if I wasn’t sure"
  },
  {
    "objectID": "slides/01-welcome-slides.html#intros",
    "href": "slides/01-welcome-slides.html#intros",
    "title": "Welcome to Stat120!",
    "section": "Intros",
    "text": "Intros\n\nName\nWhat makes you nervous about this class or term?\nSomething about yourself you are proud of\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/01-welcome-slides.html#section",
    "href": "slides/01-welcome-slides.html#section",
    "title": "Welcome to Stat120!",
    "section": "",
    "text": "Statistical Literacy is a key skill for many different courses and majors, and becoming necessary to be a responsible citizen in “the real world”. In this course, we’ll lay the foundations for statistical literacy and learn basic data analysis skills. Upon completion of the course, I expect you to be able to:\n\nWork with and describe various types of data\nUnderstand the role of variation and randomness and the principles of statistical inference\nChoose the appropriate statistical analysis for a given task and recognize when certain statistical analyses are not appropriate\nAnalyze data and apply statistical methods using R and interpret results\nCritically examine analyses of data and interpretations of results from statistical methods\nThere are no prerequisites for this course, and you do need to have any background in statistics, mathematics, or computer science to do well. If you’ve already taken Math 211, Psych 200, Psych 201, SOAN 239, or Stat 250, a different statistics class may be more appropriate for you. Please see me if this is the case."
  },
  {
    "objectID": "slides/01-welcome-slides.html#general-flow-of-the-course",
    "href": "slides/01-welcome-slides.html#general-flow-of-the-course",
    "title": "Welcome to Stat120!",
    "section": "General Flow of the Course",
    "text": "General Flow of the Course\n\nData\n\nCollecting Data\nExploratory Data Analysis\nUni- and Multi-variate\n\nIntroduction to Statistical Inference\n\nSampling Uncertainty\nConfidence Intervals\nHypothesis Tests\n\nFormal Inference\n\nSpecific settings\nWorking on projects"
  },
  {
    "objectID": "slides/01-welcome-slides.html#textbook",
    "href": "slides/01-welcome-slides.html#textbook",
    "title": "Welcome to Stat120!",
    "section": "Textbook:",
    "text": "Textbook:\n\nStatistics: Unlocking the Power of Data by Lock, Lock, Lock, Lock, and Lock. (3rd Edition)\n\nOn reserve at the library if you are not able to purchase it.\nHomework will be assigned from the chapter, so please make sure you’re working out of the right edition\nSome days I’ll ask you to skim chapters before class; other times I’ll ask you to read them after class.\n\nStat 120 Lab Manual by Chihara & Loy\n\nFreely available online\nReference for using R"
  },
  {
    "objectID": "slides/01-welcome-slides.html#what-do-we-do-in-class",
    "href": "slides/01-welcome-slides.html#what-do-we-do-in-class",
    "title": "Welcome to Stat120!",
    "section": "What do we do in class?",
    "text": "What do we do in class?\n\nDaily attendance is expected\nPlease come to class prepared. Check moodle for any before class tasks and complete the daily check-in on gradescope\nPlease bring a laptop\nFor each class, I’ll post a handout and slides. During class, you should fill in the handout. These become your reference materials for the class. I’ll bring blank printed copies for the first few weeks."
  },
  {
    "objectID": "slides/01-welcome-slides.html#assignments",
    "href": "slides/01-welcome-slides.html#assignments",
    "title": "Welcome to Stat120!",
    "section": "Assignments",
    "text": "Assignments\n\nHomework will be assigned once per week, due on gradescope by midnight on Wednesday (Friday in week 4, 7, 9)\nNo-questions-asked 12 hour grace period if you need it\n\n(grace period = no penalty, but help is generally not available anymore)\n\nAlternative due dates must be arranged in advance\nAssignment submissions should be typeset using rmarkdown OR neatly written and scanned and submitted as a PDF file.\nYou’re responsible for submitting readable work and properly marking your questions on gradescope"
  },
  {
    "objectID": "slides/01-welcome-slides.html#regrade-request-policy",
    "href": "slides/01-welcome-slides.html#regrade-request-policy",
    "title": "Welcome to Stat120!",
    "section": "Regrade request policy",
    "text": "Regrade request policy\n\nCan be submitted on gradescope within 2 weekdays after graded homework has been returned\nUse for administrative errors or obvious grading mistakes\n\n“The grader said I didn’t answer this but it’s at the bottom of the page”\n“It said the answer is 4.39 and I put 4.387”\n\nDo not use for anything that applied to the entire class\n\n“I think this mistake should only be worth 1 point instead of 2”\n“I didn’t realize we had to do X”\n\nIf you submit two or more inappropriate regrade requests, I won’t consider any more from you during the term\nCome talk to me with any questions!"
  },
  {
    "objectID": "slides/01-welcome-slides.html#exams",
    "href": "slides/01-welcome-slides.html#exams",
    "title": "Welcome to Stat120!",
    "section": "Exams",
    "text": "Exams\n\nWhile I believe most of your learning in this course will happen through working on homework and your project, part of being literate in statistics is being able to recall basic concepts and interpret analyses “on the fly”, without access to other resources\nThere will be three in-class exams, tentatively scheduled for Fridays of Week 3, 6, and 9\nIf I need to reschedule, I’ll give you at least two weeks notice.\nAny conflicts must be communicated to me in writing at least two weeks in advance to be able to schedule a make-up time\nIf an emergency arises and you’re unable to take the exam, please contact me and your class deans as soon as possible."
  },
  {
    "objectID": "slides/01-welcome-slides.html#final-project",
    "href": "slides/01-welcome-slides.html#final-project",
    "title": "Welcome to Stat120!",
    "section": "Final Project",
    "text": "Final Project\n\nGroup data analysis project\nPoster session on the last day of class\nFinal paper due during finals period\nShort proposal is due before the midterm break"
  },
  {
    "objectID": "slides/01-welcome-slides.html#how-will-my-final-grade-be-calculated",
    "href": "slides/01-welcome-slides.html#how-will-my-final-grade-be-calculated",
    "title": "Welcome to Stat120!",
    "section": "How will my final grade be calculated?",
    "text": "How will my final grade be calculated?\n\n15% homework\n5% daily check-ins (lowest 3 will be dropped)\n5% attendance and participation in group work\n16.33% each exam (50% total)\n15% final paper\n10% final project\nLetter grades will be assigned based on the usual grading scale (A = 93%+, A- = 90-92.9%, B+ = 88-89.9%, B = 83-87.9, etc.)"
  },
  {
    "objectID": "slides/01-welcome-slides.html#advice-from-past-intro-stat-students",
    "href": "slides/01-welcome-slides.html#advice-from-past-intro-stat-students",
    "title": "Welcome to Stat120!",
    "section": "Advice from past intro stat students:",
    "text": "Advice from past intro stat students:\n\nDon’t be afraid to ask questions. Even if you think they’re really stupid, asking them could help you understand so many concepts.\nEven if homework is due weekly, try to do it throughout the week so you can check your understanding between class periods. Ask Amanda for help - especially in R! It’s usually a quick fix and much easier than breaking your brain over a small error.\nDo the work! The class really is not too difficult if you do what Amanda assigns/recommends. Readings, daily preps, HWs were all very helpful for learning.\nTo keep up with the work and really nail down the concepts because everything connects and if you don’t understand something in the moment it will make things harder in the future\nDon’t be afraid to ask questions, in and out of class, and don’t try to figure everything out on your own. Talking through problems with friends, people from stats lab, or Amanda helps a lot!\nDo NOT procrastinate on the homework because a lot of times I had trouble knitting and that is not ideal if you wait until the last minute to turn in the homework.\nSTART. THE HOMEWORK. EARLY. You may think “oh, it’s a 100 level course, the homework can’t take THAT long” but it can. It CAN take that long. And it will.\nAsk questions! Prof. Luby is extremely helpful and approachable\ni would say to not be afraid of using R. it really isnt as bad as it looks and can be pretty fun to use if you just learn the fundamentals of it"
  },
  {
    "objectID": "slides/01-welcome-slides.html#getting-help",
    "href": "slides/01-welcome-slides.html#getting-help",
    "title": "Welcome to Stat120!",
    "section": "Getting Help",
    "text": "Getting Help\nThis course was not designed for you to do on your own in your dorm room every week, and I expect you to need some help on most assignments.\n\nOffice Hours are held in CMC 307. You can come and go as you please! These are open to all students in the class so you may need to wait a little while to have your specific question answered. These are best for homework questions and conceptual questions about material\n\n\nIndividual Appointments will be available throughout the week. Appointment slots open 5 days in advance and close 2 hours in advance. Please use these for in-depth conversations about grade concerns, project consultations, or if you need extra help on a specific concept. You’re welcome to come as a group, but please note that 15 minutes goes by fast!\n\n\nStat Lab is staffed by friendly and knowledgeable student assistants who can help you with R questions that arise on your homework or projects. Please come prepared with your attempt, your class notes, and your lab manual to make the most of your time.\n\n\nSlack is an asychronous communication platform where you can also ask homework questions anytime! I’ll respond to messages at least twice per weekday. If you see someone ask a question that you know the answer to, please respond!"
  },
  {
    "objectID": "slides/01-welcome-slides.html#office-hours-tentative",
    "href": "slides/01-welcome-slides.html#office-hours-tentative",
    "title": "Welcome to Stat120!",
    "section": "Office hours (tentative)",
    "text": "Office hours (tentative)\n\n\n\nDay\nTime\nType\nLocation\n\n\n\n\nMonday\n12:30-1:30\nDrop-in\nCMC 307\n\n\nTuesday\n2-3\nDrop-in\nCMC 307\n\n\nWednesday\n3-41\nDrop-in\nCMC 307\n\n\nFriday\n10-112\nDrop-in\nCMC 307\n\n\n\nStat120 PriorityStat340 Priority"
  },
  {
    "objectID": "slides/01-welcome-slides.html#communication",
    "href": "slides/01-welcome-slides.html#communication",
    "title": "Welcome to Stat120!",
    "section": "Communication",
    "text": "Communication\n\n\nMoodle: assignments, slides, and grades\nSlack: homework questions, announcements, discussion\nEmail: personal matters, time-sensitive announcements\n\n\n\nSlack is the fastest way to reach me. I typically will respond to messages 3x per weekday. I try to respond to emails within 48 hours. I’m online sporadically on evenings and weekends to devote time to family and rest – I hope you also use this time to reset and recharge!"
  },
  {
    "objectID": "slides/01-welcome-slides.html#the-genius-myth",
    "href": "slides/01-welcome-slides.html#the-genius-myth",
    "title": "Welcome to Stat120!",
    "section": "The “Genius Myth”",
    "text": "The “Genius Myth”\nIt’s sometimes easy to buy into the “genius myth” when it comes to math/stat courses: that you need to be a “math person” and have some innate mathematical ability in order to do well or become a statistics major. This could not be further from the truth! The best statisticians don’t necessarily have the “best” math or programming background, but are people that are able to formulate interesting questions and use math and programming to rigorously answer those questions. Many of the best statisticians I know became statisticians because they were initially interested in something else (biology, public health, psychology, neuroscience, physics, etc.) and realized that being able to answer important questions with data was not only valuable but fun and interesting. Being able to perform interesting statistical analyses is a skill that is learned, not an innate ability, and working hard at developing that skill is the point of this course."
  },
  {
    "objectID": "slides/01-welcome-slides.html#academic-integrity",
    "href": "slides/01-welcome-slides.html#academic-integrity",
    "title": "Welcome to Stat120!",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nYou are expected to follow Carleton’s policies regarding academic integrity. I encourage you to discuss the homework problems with others and use the resources available to you to try to figure out tough problems. You should code and write up your solutions on your own. Exams must be done by yourself without communicating with others; all work must be your own. The use of textbook solution manuals (physical or online), course materials from other students, or materials from previous versions of this course are not allowed. Copying, paraphrasing, summarizing, or submitting work generated by anyone but yourself without proper attribution is considered academic dishonesty (this includes output from LLMs).\nPlease ask if you are unsure of whether or not your actions are complying with the assignment/exam/project instructions. Always default to acknowledging any help received. Cases of suspected academic dishonesty are handled by the Provost’s Office and I am obligated to report any suspected violations of this policy."
  },
  {
    "objectID": "slides/01-welcome-slides.html#more-on-ai",
    "href": "slides/01-welcome-slides.html#more-on-ai",
    "title": "Welcome to Stat120!",
    "section": "More on “AI”",
    "text": "More on “AI”\nLarge-language models (e.g. ChatGPT, Gemini, etc.) should only be used for help interpreting R’s error messages or suggestions for your own code once you have already attempted the problem. You should not copy and paste course material into or out of an AI text generator.\nI also have a few rules in place to protect my intellectual property. You may not record my lectures using tools such as Otter.ai or upload any video or audio recordings to generate transcripts or study notes. You may not upload my course materials (slides, assignment prompts, note sets, etc.) into AI tools or homework help sites (such as chegg).\n“AI” tools are new for all of us and it’s OK to have questions about what is and isn’t appropriate!"
  },
  {
    "objectID": "slides/01-welcome-slides.html#diversity-inclusion",
    "href": "slides/01-welcome-slides.html#diversity-inclusion",
    "title": "Welcome to Stat120!",
    "section": "Diversity & Inclusion",
    "text": "Diversity & Inclusion\nWe all come to class with different backgrounds and experiences, and this diversity makes our class environment richer. We value diversity and inclusion, and are committed to a climate of mutual respect and full participation in and out of the classroom. This class strives to be a learning environment that is usable, equitable, inclusive and welcoming, regardless of race, ethnicity, religion, gender and gender identities, sexual orientation, ability, socioeconomic background, and nationality. If you anticipate or experience any barriers to learning, please discuss your concerns with me."
  },
  {
    "objectID": "slides/01-welcome-slides.html#accomodations",
    "href": "slides/01-welcome-slides.html#accomodations",
    "title": "Welcome to Stat120!",
    "section": "Accomodations",
    "text": "Accomodations\nCarleton College is committed to providing equitable access to learning opportunities for all students. The Office of Accessibility Resources (Henry House, 107 Union Street) is the campus office that collaborates with students who have disabilities to provide and/or arrange reasonable accommodations. If you have, or think you may have, a disability, please contact OAR@carleton.edu to arrange a confidential discussion regarding equitable access and reasonable accommodations. You are also welcome to contact me privately to discuss your academic needs. However, all disability-related accommodations must be arranged, in advance, through OAR."
  },
  {
    "objectID": "slides/01-welcome-slides.html#title-ix",
    "href": "slides/01-welcome-slides.html#title-ix",
    "title": "Welcome to Stat120!",
    "section": "Title IX",
    "text": "Title IX\nPlease be aware that all faculty are “responsible employees”, which means that if you tell me about a situation involving sexual harassment, sexual assault, dating violence, domestic violence, or stalking, I must share that information with the Title IX Coordinator. Although I have to make this notification, you will control how your case will be handled, including whether or not you wish to meet with the Title IX coordinator or pursue a formal complaint."
  },
  {
    "objectID": "slides/01-welcome-slides.html#take-care-of-yourself",
    "href": "slides/01-welcome-slides.html#take-care-of-yourself",
    "title": "Welcome to Stat120!",
    "section": "Take care of yourself",
    "text": "Take care of yourself\nDo your best to maintain a healthy lifestyle this semester by wearing a mask if you don’t feel well, eating a vegetable every day, exercising, avoiding excessive drug and alcohol use, getting enough sleep, and taking some time to relax. Your mental health is more important than your grade in this course. There are many helpful resources available on campus and an important part of the college experience is learning how to ask for help. If you are experiencing mental health symptoms as a result of coursework, please speak with me so we can address the problem together."
  },
  {
    "objectID": "slides/01-welcome-slides.html#the-palmerpenguins-data",
    "href": "slides/01-welcome-slides.html#the-palmerpenguins-data",
    "title": "Welcome to Stat120!",
    "section": "The palmerpenguins data",
    "text": "The palmerpenguins data\n\nData were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network."
  },
  {
    "objectID": "slides/01-welcome-slides.html#data-as-a-spreadsheet",
    "href": "slides/01-welcome-slides.html#data-as-a-spreadsheet",
    "title": "Welcome to Stat120!",
    "section": "Data as a “spreadsheet”",
    "text": "Data as a “spreadsheet”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007"
  },
  {
    "objectID": "slides/01-welcome-slides.html#definitions",
    "href": "slides/01-welcome-slides.html#definitions",
    "title": "Welcome to Stat120!",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\nCases\n\n\nAlso called “units” or “observations”. Generally correspond to rows in a dataset. What does each “data point” represent\n\n\n\n\n\n\n\n\nVariables\n\n\nCharacteristics that are recorded for each case. Generally correspond to columns in the dataset"
  },
  {
    "objectID": "slides/01-welcome-slides.html#types-of-variables",
    "href": "slides/01-welcome-slides.html#types-of-variables",
    "title": "Welcome to Stat120!",
    "section": "Types of Variables",
    "text": "Types of Variables\n\n\n\n\n\nflowchart LR\n  A(Categorical) --&gt; B(Ordered/Ordinal)\n  A --&gt; C(Binary)\n  A --&gt; D(Categorical)\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  A(Quantitative) --&gt; B(Discrete)\n  A --&gt; C(Continuous)"
  },
  {
    "objectID": "slides/01-welcome-slides.html#explanatory-vs-response-variable",
    "href": "slides/01-welcome-slides.html#explanatory-vs-response-variable",
    "title": "Welcome to Stat120!",
    "section": "Explanatory vs Response Variable",
    "text": "Explanatory vs Response Variable\nAn explanatory variable is the variable you believe causes, predicts, or influences another variable, while the response variable is the outcome you are measuring or interested in.\nThe explanatory variables explain the response variable"
  },
  {
    "objectID": "slides/01-welcome-slides.html#examples",
    "href": "slides/01-welcome-slides.html#examples",
    "title": "Welcome to Stat120!",
    "section": "Examples",
    "text": "Examples\nFor each of the following, indicate the cases and the variables. For each variable, label it as quantitative or categorical. If you see clear explanatory or response variables, indicate those as well."
  },
  {
    "objectID": "slides/01-welcome-slides.html#example-3.1-penguins",
    "href": "slides/01-welcome-slides.html#example-3.1-penguins",
    "title": "Welcome to Stat120!",
    "section": "Example 3.1: Penguins",
    "text": "Example 3.1: Penguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.2\n19.6\n195\n4675\nmale\n2007\n\n\nAdelie\nTorgersen\n34.1\n18.1\n193\n3475\nNA\n2007\n\n\nAdelie\nTorgersen\n42.0\n20.2\n190\n4250\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.1\n186\n3300\nNA\n2007\n\n\nAdelie\nTorgersen\n37.8\n17.3\n180\n3700\nNA\n2007\n\n\nAdelie\nTorgersen\n41.1\n17.6\n182\n3200\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.6\n21.2\n191\n3800\nmale\n2007\n\n\nAdelie\nTorgersen\n34.6\n21.1\n198\n4400\nmale\n2007\n\n\nAdelie\nTorgersen\n36.6\n17.8\n185\n3700\nfemale\n2007\n\n\nAdelie\nTorgersen\n38.7\n19.0\n195\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n42.5\n20.7\n197\n4500\nmale\n2007\n\n\nAdelie\nTorgersen\n34.4\n18.4\n184\n3325\nfemale\n2007\n\n\nAdelie\nTorgersen\n46.0\n21.5\n194\n4200\nmale\n2007\n\n\nAdelie\nBiscoe\n37.8\n18.3\n174\n3400\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.7\n18.7\n180\n3600\nmale\n2007\n\n\nAdelie\nBiscoe\n35.9\n19.2\n189\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n38.2\n18.1\n185\n3950\nmale\n2007\n\n\nAdelie\nBiscoe\n38.8\n17.2\n180\n3800\nmale\n2007\n\n\nAdelie\nBiscoe\n35.3\n18.9\n187\n3800\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.6\n18.6\n183\n3550\nmale\n2007\n\n\nAdelie\nBiscoe\n40.5\n17.9\n187\n3200\nfemale\n2007\n\n\nAdelie\nBiscoe\n37.9\n18.6\n172\n3150\nfemale\n2007\n\n\nAdelie\nBiscoe\n40.5\n18.9\n180\n3950\nmale\n2007\n\n\nAdelie\nDream\n39.5\n16.7\n178\n3250\nfemale\n2007\n\n\nAdelie\nDream\n37.2\n18.1\n178\n3900\nmale\n2007\n\n\nAdelie\nDream\n39.5\n17.8\n188\n3300\nfemale\n2007\n\n\nAdelie\nDream\n40.9\n18.9\n184\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.4\n17.0\n195\n3325\nfemale\n2007\n\n\nAdelie\nDream\n39.2\n21.1\n196\n4150\nmale\n2007\n\n\nAdelie\nDream\n38.8\n20.0\n190\n3950\nmale\n2007\n\n\nAdelie\nDream\n42.2\n18.5\n180\n3550\nfemale\n2007\n\n\nAdelie\nDream\n37.6\n19.3\n181\n3300\nfemale\n2007\n\n\nAdelie\nDream\n39.8\n19.1\n184\n4650\nmale\n2007\n\n\nAdelie\nDream\n36.5\n18.0\n182\n3150\nfemale\n2007\n\n\nAdelie\nDream\n40.8\n18.4\n195\n3900\nmale\n2007\n\n\nAdelie\nDream\n36.0\n18.5\n186\n3100\nfemale\n2007\n\n\nAdelie\nDream\n44.1\n19.7\n196\n4400\nmale\n2007\n\n\nAdelie\nDream\n37.0\n16.9\n185\n3000\nfemale\n2007\n\n\nAdelie\nDream\n39.6\n18.8\n190\n4600\nmale\n2007\n\n\nAdelie\nDream\n41.1\n19.0\n182\n3425\nmale\n2007\n\n\nAdelie\nDream\n37.5\n18.9\n179\n2975\nNA\n2007\n\n\nAdelie\nDream\n36.0\n17.9\n190\n3450\nfemale\n2007\n\n\nAdelie\nDream\n42.3\n21.2\n191\n4150\nmale\n2007\n\n\nAdelie\nBiscoe\n39.6\n17.7\n186\n3500\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.1\n18.9\n188\n4300\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n190\n3450\nfemale\n2008\n\n\nAdelie\nBiscoe\n42.0\n19.5\n200\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n34.5\n18.1\n187\n2900\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.4\n18.6\n191\n3700\nmale\n2008\n\n\nAdelie\nBiscoe\n39.0\n17.5\n186\n3550\nfemale\n2008\n\n\nAdelie\nBiscoe\n40.6\n18.8\n193\n3800\nmale\n2008\n\n\nAdelie\nBiscoe\n36.5\n16.6\n181\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n37.6\n19.1\n194\n3750\nmale\n2008\n\n\nAdelie\nBiscoe\n35.7\n16.9\n185\n3150\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.3\n21.1\n195\n4400\nmale\n2008\n\n\nAdelie\nBiscoe\n37.6\n17.0\n185\n3600\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n18.2\n192\n4050\nmale\n2008\n\n\nAdelie\nBiscoe\n36.4\n17.1\n184\n2850\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.6\n18.0\n192\n3950\nmale\n2008\n\n\nAdelie\nBiscoe\n35.5\n16.2\n195\n3350\nfemale\n2008\n\n\nAdelie\nBiscoe\n41.1\n19.1\n188\n4100\nmale\n2008\n\n\nAdelie\nTorgersen\n35.9\n16.6\n190\n3050\nfemale\n2008\n\n\nAdelie\nTorgersen\n41.8\n19.4\n198\n4450\nmale\n2008\n\n\nAdelie\nTorgersen\n33.5\n19.0\n190\n3600\nfemale\n2008\n\n\nAdelie\nTorgersen\n39.7\n18.4\n190\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n39.6\n17.2\n196\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n45.8\n18.9\n197\n4150\nmale\n2008\n\n\nAdelie\nTorgersen\n35.5\n17.5\n190\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.8\n18.5\n195\n4250\nmale\n2008\n\n\nAdelie\nTorgersen\n40.9\n16.8\n191\n3700\nfemale\n2008\n\n\nAdelie\nTorgersen\n37.2\n19.4\n184\n3900\nmale\n2008\n\n\nAdelie\nTorgersen\n36.2\n16.1\n187\n3550\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.1\n19.1\n195\n4000\nmale\n2008\n\n\nAdelie\nTorgersen\n34.6\n17.2\n189\n3200\nfemale\n2008\n\n\nAdelie\nTorgersen\n42.9\n17.6\n196\n4700\nmale\n2008\n\n\nAdelie\nTorgersen\n36.7\n18.8\n187\n3800\nfemale\n2008\n\n\nAdelie\nTorgersen\n35.1\n19.4\n193\n4200\nmale\n2008\n\n\nAdelie\nDream\n37.3\n17.8\n191\n3350\nfemale\n2008\n\n\nAdelie\nDream\n41.3\n20.3\n194\n3550\nmale\n2008\n\n\nAdelie\nDream\n36.3\n19.5\n190\n3800\nmale\n2008\n\n\nAdelie\nDream\n36.9\n18.6\n189\n3500\nfemale\n2008\n\n\nAdelie\nDream\n38.3\n19.2\n189\n3950\nmale\n2008\n\n\nAdelie\nDream\n38.9\n18.8\n190\n3600\nfemale\n2008\n\n\nAdelie\nDream\n35.7\n18.0\n202\n3550\nfemale\n2008\n\n\nAdelie\nDream\n41.1\n18.1\n205\n4300\nmale\n2008\n\n\nAdelie\nDream\n34.0\n17.1\n185\n3400\nfemale\n2008\n\n\nAdelie\nDream\n39.6\n18.1\n186\n4450\nmale\n2008\n\n\nAdelie\nDream\n36.2\n17.3\n187\n3300\nfemale\n2008\n\n\nAdelie\nDream\n40.8\n18.9\n208\n4300\nmale\n2008\n\n\nAdelie\nDream\n38.1\n18.6\n190\n3700\nfemale\n2008\n\n\nAdelie\nDream\n40.3\n18.5\n196\n4350\nmale\n2008\n\n\nAdelie\nDream\n33.1\n16.1\n178\n2900\nfemale\n2008\n\n\nAdelie\nDream\n43.2\n18.5\n192\n4100\nmale\n2008\n\n\nAdelie\nBiscoe\n35.0\n17.9\n192\n3725\nfemale\n2009\n\n\nAdelie\nBiscoe\n41.0\n20.0\n203\n4725\nmale\n2009\n\n\nAdelie\nBiscoe\n37.7\n16.0\n183\n3075\nfemale\n2009\n\n\nAdelie\nBiscoe\n37.8\n20.0\n190\n4250\nmale\n2009\n\n\nAdelie\nBiscoe\n37.9\n18.6\n193\n2925\nfemale\n2009\n\n\nAdelie\nBiscoe\n39.7\n18.9\n184\n3550\nmale\n2009\n\n\nAdelie\nBiscoe\n38.6\n17.2\n199\n3750\nfemale\n2009\n\n\nAdelie\nBiscoe\n38.2\n20.0\n190\n3900\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n17.0\n181\n3175\nfemale\n2009\n\n\nAdelie\nBiscoe\n43.2\n19.0\n197\n4775\nmale\n2009\n\n\nAdelie\nBiscoe\n38.1\n16.5\n198\n3825\nfemale\n2009\n\n\nAdelie\nBiscoe\n45.6\n20.3\n191\n4600\nmale\n2009\n\n\nAdelie\nBiscoe\n39.7\n17.7\n193\n3200\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.2\n19.5\n197\n4275\nmale\n2009\n\n\nAdelie\nBiscoe\n39.6\n20.7\n191\n3900\nfemale\n2009\n\n\nAdelie\nBiscoe\n42.7\n18.3\n196\n4075\nmale\n2009\n\n\nAdelie\nTorgersen\n38.6\n17.0\n188\n2900\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.3\n20.5\n199\n3775\nmale\n2009\n\n\nAdelie\nTorgersen\n35.7\n17.0\n189\n3350\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.1\n18.6\n189\n3325\nmale\n2009\n\n\nAdelie\nTorgersen\n36.2\n17.2\n187\n3150\nfemale\n2009\n\n\nAdelie\nTorgersen\n37.7\n19.8\n198\n3500\nmale\n2009\n\n\nAdelie\nTorgersen\n40.2\n17.0\n176\n3450\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.4\n18.5\n202\n3875\nmale\n2009\n\n\nAdelie\nTorgersen\n35.2\n15.9\n186\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n40.6\n19.0\n199\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.8\n17.6\n191\n3275\nfemale\n2009\n\n\nAdelie\nTorgersen\n41.5\n18.3\n195\n4300\nmale\n2009\n\n\nAdelie\nTorgersen\n39.0\n17.1\n191\n3050\nfemale\n2009\n\n\nAdelie\nTorgersen\n44.1\n18.0\n210\n4000\nmale\n2009\n\n\nAdelie\nTorgersen\n38.5\n17.9\n190\n3325\nfemale\n2009\n\n\nAdelie\nTorgersen\n43.1\n19.2\n197\n3500\nmale\n2009\n\n\nAdelie\nDream\n36.8\n18.5\n193\n3500\nfemale\n2009\n\n\nAdelie\nDream\n37.5\n18.5\n199\n4475\nmale\n2009\n\n\nAdelie\nDream\n38.1\n17.6\n187\n3425\nfemale\n2009\n\n\nAdelie\nDream\n41.1\n17.5\n190\n3900\nmale\n2009\n\n\nAdelie\nDream\n35.6\n17.5\n191\n3175\nfemale\n2009\n\n\nAdelie\nDream\n40.2\n20.1\n200\n3975\nmale\n2009\n\n\nAdelie\nDream\n37.0\n16.5\n185\n3400\nfemale\n2009\n\n\nAdelie\nDream\n39.7\n17.9\n193\n4250\nmale\n2009\n\n\nAdelie\nDream\n40.2\n17.1\n193\n3400\nfemale\n2009\n\n\nAdelie\nDream\n40.6\n17.2\n187\n3475\nmale\n2009\n\n\nAdelie\nDream\n32.1\n15.5\n188\n3050\nfemale\n2009\n\n\nAdelie\nDream\n40.7\n17.0\n190\n3725\nmale\n2009\n\n\nAdelie\nDream\n37.3\n16.8\n192\n3000\nfemale\n2009\n\n\nAdelie\nDream\n39.0\n18.7\n185\n3650\nmale\n2009\n\n\nAdelie\nDream\n39.2\n18.6\n190\n4250\nmale\n2009\n\n\nAdelie\nDream\n36.6\n18.4\n184\n3475\nfemale\n2009\n\n\nAdelie\nDream\n36.0\n17.8\n195\n3450\nfemale\n2009\n\n\nAdelie\nDream\n37.8\n18.1\n193\n3750\nmale\n2009\n\n\nAdelie\nDream\n36.0\n17.1\n187\n3700\nfemale\n2009\n\n\nAdelie\nDream\n41.5\n18.5\n201\n4000\nmale\n2009\n\n\nGentoo\nBiscoe\n46.1\n13.2\n211\n4500\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n16.3\n230\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n48.7\n14.1\n210\n4450\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.2\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n47.6\n14.5\n215\n5400\nmale\n2007\n\n\nGentoo\nBiscoe\n46.5\n13.5\n210\n4550\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.4\n14.6\n211\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.7\n15.3\n219\n5200\nmale\n2007\n\n\nGentoo\nBiscoe\n43.3\n13.4\n209\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.8\n15.4\n215\n5150\nmale\n2007\n\n\nGentoo\nBiscoe\n40.9\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.0\n16.1\n216\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n45.5\n13.7\n214\n4650\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.4\n14.6\n213\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n45.8\n14.6\n210\n4200\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.3\n15.7\n217\n5850\nmale\n2007\n\n\nGentoo\nBiscoe\n42.0\n13.5\n210\n4150\nfemale\n2007\n\n\nGentoo\nBiscoe\n49.2\n15.2\n221\n6300\nmale\n2007\n\n\nGentoo\nBiscoe\n46.2\n14.5\n209\n4800\nfemale\n2007\n\n\nGentoo\nBiscoe\n48.7\n15.1\n222\n5350\nmale\n2007\n\n\nGentoo\nBiscoe\n50.2\n14.3\n218\n5700\nmale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.5\n14.5\n213\n4400\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.3\n15.8\n215\n5050\nmale\n2007\n\n\nGentoo\nBiscoe\n42.9\n13.1\n215\n5000\nfemale\n2007\n\n\nGentoo\nBiscoe\n46.1\n15.1\n215\n5100\nmale\n2007\n\n\nGentoo\nBiscoe\n44.5\n14.3\n216\n4100\nNA\n2007\n\n\nGentoo\nBiscoe\n47.8\n15.0\n215\n5650\nmale\n2007\n\n\nGentoo\nBiscoe\n48.2\n14.3\n210\n4600\nfemale\n2007\n\n\nGentoo\nBiscoe\n50.0\n15.3\n220\n5550\nmale\n2007\n\n\nGentoo\nBiscoe\n47.3\n15.3\n222\n5250\nmale\n2007\n\n\nGentoo\nBiscoe\n42.8\n14.2\n209\n4700\nfemale\n2007\n\n\nGentoo\nBiscoe\n45.1\n14.5\n207\n5050\nfemale\n2007\n\n\nGentoo\nBiscoe\n59.6\n17.0\n230\n6050\nmale\n2007\n\n\nGentoo\nBiscoe\n49.1\n14.8\n220\n5150\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.4\n16.3\n220\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n42.6\n13.7\n213\n4950\nfemale\n2008\n\n\nGentoo\nBiscoe\n44.4\n17.3\n219\n5250\nmale\n2008\n\n\nGentoo\nBiscoe\n44.0\n13.6\n208\n4350\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.7\n15.7\n208\n5350\nmale\n2008\n\n\nGentoo\nBiscoe\n42.7\n13.7\n208\n3950\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n16.0\n225\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.7\n210\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.6\n15.0\n216\n4750\nmale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n222\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n43.6\n13.9\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n13.9\n210\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.5\n15.9\n225\n5400\nmale\n2008\n\n\nGentoo\nBiscoe\n44.9\n13.3\n213\n5100\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n15.8\n215\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n46.6\n14.2\n210\n4850\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.5\n14.1\n220\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.1\n14.4\n210\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.1\n15.0\n225\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.4\n217\n4900\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.0\n15.4\n220\n5050\nmale\n2008\n\n\nGentoo\nBiscoe\n43.8\n13.9\n208\n4300\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.5\n15.0\n220\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n43.2\n14.5\n208\n4450\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.4\n15.3\n224\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n45.3\n13.8\n208\n4200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.9\n221\n5300\nmale\n2008\n\n\nGentoo\nBiscoe\n45.7\n13.9\n214\n4400\nfemale\n2008\n\n\nGentoo\nBiscoe\n54.3\n15.7\n231\n5650\nmale\n2008\n\n\nGentoo\nBiscoe\n45.8\n14.2\n219\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n49.8\n16.8\n230\n5700\nmale\n2008\n\n\nGentoo\nBiscoe\n46.2\n14.4\n214\n4650\nNA\n2008\n\n\nGentoo\nBiscoe\n49.5\n16.2\n229\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n43.5\n14.2\n220\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n50.7\n15.0\n223\n5550\nmale\n2008\n\n\nGentoo\nBiscoe\n47.7\n15.0\n216\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.6\n221\n5000\nmale\n2008\n\n\nGentoo\nBiscoe\n48.2\n15.6\n221\n5100\nmale\n2008\n\n\nGentoo\nBiscoe\n46.5\n14.8\n217\n5200\nfemale\n2008\n\n\nGentoo\nBiscoe\n46.4\n15.0\n216\n4700\nfemale\n2008\n\n\nGentoo\nBiscoe\n48.6\n16.0\n230\n5800\nmale\n2008\n\n\nGentoo\nBiscoe\n47.5\n14.2\n209\n4600\nfemale\n2008\n\n\nGentoo\nBiscoe\n51.1\n16.3\n220\n6000\nmale\n2008\n\n\nGentoo\nBiscoe\n45.2\n13.8\n215\n4750\nfemale\n2008\n\n\nGentoo\nBiscoe\n45.2\n16.4\n223\n5950\nmale\n2008\n\n\nGentoo\nBiscoe\n49.1\n14.5\n212\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.5\n15.6\n221\n5450\nmale\n2009\n\n\nGentoo\nBiscoe\n47.4\n14.6\n212\n4725\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.0\n15.9\n224\n5350\nmale\n2009\n\n\nGentoo\nBiscoe\n44.9\n13.8\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n17.3\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n43.4\n14.4\n218\n4600\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.3\n14.2\n218\n5300\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n14.0\n212\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.1\n17.0\n230\n5550\nmale\n2009\n\n\nGentoo\nBiscoe\n47.5\n15.0\n218\n4950\nfemale\n2009\n\n\nGentoo\nBiscoe\n52.2\n17.1\n228\n5400\nmale\n2009\n\n\nGentoo\nBiscoe\n45.5\n14.5\n212\n4750\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.5\n16.1\n224\n5650\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n14.7\n214\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.8\n15.7\n226\n5200\nmale\n2009\n\n\nGentoo\nBiscoe\n49.4\n15.8\n216\n4925\nmale\n2009\n\n\nGentoo\nBiscoe\n46.9\n14.6\n222\n4875\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.4\n14.4\n203\n4625\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.1\n16.5\n225\n5250\nmale\n2009\n\n\nGentoo\nBiscoe\n48.5\n15.0\n219\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.9\n17.0\n228\n5600\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n15.5\n215\n4975\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.1\n15.0\n228\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n47.3\n13.8\n216\n4725\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n16.1\n215\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n41.7\n14.7\n210\n4700\nfemale\n2009\n\n\nGentoo\nBiscoe\n53.4\n15.8\n219\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n43.3\n14.0\n208\n4575\nfemale\n2009\n\n\nGentoo\nBiscoe\n48.1\n15.1\n209\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n50.5\n15.2\n216\n5000\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.8\n15.9\n229\n5950\nmale\n2009\n\n\nGentoo\nBiscoe\n43.5\n15.2\n213\n4650\nfemale\n2009\n\n\nGentoo\nBiscoe\n51.5\n16.3\n230\n5500\nmale\n2009\n\n\nGentoo\nBiscoe\n46.2\n14.1\n217\n4375\nfemale\n2009\n\n\nGentoo\nBiscoe\n55.1\n16.0\n230\n5850\nmale\n2009\n\n\nGentoo\nBiscoe\n44.5\n15.7\n217\n4875\nNA\n2009\n\n\nGentoo\nBiscoe\n48.8\n16.2\n222\n6000\nmale\n2009\n\n\nGentoo\nBiscoe\n47.2\n13.7\n214\n4925\nfemale\n2009\n\n\nGentoo\nBiscoe\nNA\nNA\nNA\nNA\nNA\n2009\n\n\nGentoo\nBiscoe\n46.8\n14.3\n215\n4850\nfemale\n2009\n\n\nGentoo\nBiscoe\n50.4\n15.7\n222\n5750\nmale\n2009\n\n\nGentoo\nBiscoe\n45.2\n14.8\n212\n5200\nfemale\n2009\n\n\nGentoo\nBiscoe\n49.9\n16.1\n213\n5400\nmale\n2009\n\n\nChinstrap\nDream\n46.5\n17.9\n192\n3500\nfemale\n2007\n\n\nChinstrap\nDream\n50.0\n19.5\n196\n3900\nmale\n2007\n\n\nChinstrap\nDream\n51.3\n19.2\n193\n3650\nmale\n2007\n\n\nChinstrap\nDream\n45.4\n18.7\n188\n3525\nfemale\n2007\n\n\nChinstrap\nDream\n52.7\n19.8\n197\n3725\nmale\n2007\n\n\nChinstrap\nDream\n45.2\n17.8\n198\n3950\nfemale\n2007\n\n\nChinstrap\nDream\n46.1\n18.2\n178\n3250\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n18.2\n197\n3750\nmale\n2007\n\n\nChinstrap\nDream\n46.0\n18.9\n195\n4150\nfemale\n2007\n\n\nChinstrap\nDream\n51.3\n19.9\n198\n3700\nmale\n2007\n\n\nChinstrap\nDream\n46.6\n17.8\n193\n3800\nfemale\n2007\n\n\nChinstrap\nDream\n51.7\n20.3\n194\n3775\nmale\n2007\n\n\nChinstrap\nDream\n47.0\n17.3\n185\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n18.1\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n45.9\n17.1\n190\n3575\nfemale\n2007\n\n\nChinstrap\nDream\n50.5\n19.6\n201\n4050\nmale\n2007\n\n\nChinstrap\nDream\n50.3\n20.0\n197\n3300\nmale\n2007\n\n\nChinstrap\nDream\n58.0\n17.8\n181\n3700\nfemale\n2007\n\n\nChinstrap\nDream\n46.4\n18.6\n190\n3450\nfemale\n2007\n\n\nChinstrap\nDream\n49.2\n18.2\n195\n4400\nmale\n2007\n\n\nChinstrap\nDream\n42.4\n17.3\n181\n3600\nfemale\n2007\n\n\nChinstrap\nDream\n48.5\n17.5\n191\n3400\nmale\n2007\n\n\nChinstrap\nDream\n43.2\n16.6\n187\n2900\nfemale\n2007\n\n\nChinstrap\nDream\n50.6\n19.4\n193\n3800\nmale\n2007\n\n\nChinstrap\nDream\n46.7\n17.9\n195\n3300\nfemale\n2007\n\n\nChinstrap\nDream\n52.0\n19.0\n197\n4150\nmale\n2007\n\n\nChinstrap\nDream\n50.5\n18.4\n200\n3400\nfemale\n2008\n\n\nChinstrap\nDream\n49.5\n19.0\n200\n3800\nmale\n2008\n\n\nChinstrap\nDream\n46.4\n17.8\n191\n3700\nfemale\n2008\n\n\nChinstrap\nDream\n52.8\n20.0\n205\n4550\nmale\n2008\n\n\nChinstrap\nDream\n40.9\n16.6\n187\n3200\nfemale\n2008\n\n\nChinstrap\nDream\n54.2\n20.8\n201\n4300\nmale\n2008\n\n\nChinstrap\nDream\n42.5\n16.7\n187\n3350\nfemale\n2008\n\n\nChinstrap\nDream\n51.0\n18.8\n203\n4100\nmale\n2008\n\n\nChinstrap\nDream\n49.7\n18.6\n195\n3600\nmale\n2008\n\n\nChinstrap\nDream\n47.5\n16.8\n199\n3900\nfemale\n2008\n\n\nChinstrap\nDream\n47.6\n18.3\n195\n3850\nfemale\n2008\n\n\nChinstrap\nDream\n52.0\n20.7\n210\n4800\nmale\n2008\n\n\nChinstrap\nDream\n46.9\n16.6\n192\n2700\nfemale\n2008\n\n\nChinstrap\nDream\n53.5\n19.9\n205\n4500\nmale\n2008\n\n\nChinstrap\nDream\n49.0\n19.5\n210\n3950\nmale\n2008\n\n\nChinstrap\nDream\n46.2\n17.5\n187\n3650\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n19.1\n196\n3550\nmale\n2008\n\n\nChinstrap\nDream\n45.5\n17.0\n196\n3500\nfemale\n2008\n\n\nChinstrap\nDream\n50.9\n17.9\n196\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n50.8\n18.5\n201\n4450\nmale\n2009\n\n\nChinstrap\nDream\n50.1\n17.9\n190\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.0\n19.6\n212\n4300\nmale\n2009\n\n\nChinstrap\nDream\n51.5\n18.7\n187\n3250\nmale\n2009\n\n\nChinstrap\nDream\n49.8\n17.3\n198\n3675\nfemale\n2009\n\n\nChinstrap\nDream\n48.1\n16.4\n199\n3325\nfemale\n2009\n\n\nChinstrap\nDream\n51.4\n19.0\n201\n3950\nmale\n2009\n\n\nChinstrap\nDream\n45.7\n17.3\n193\n3600\nfemale\n2009\n\n\nChinstrap\nDream\n50.7\n19.7\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n42.5\n17.3\n187\n3350\nfemale\n2009\n\n\nChinstrap\nDream\n52.2\n18.8\n197\n3450\nmale\n2009\n\n\nChinstrap\nDream\n45.2\n16.6\n191\n3250\nfemale\n2009\n\n\nChinstrap\nDream\n49.3\n19.9\n203\n4050\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.8\n202\n3800\nmale\n2009\n\n\nChinstrap\nDream\n45.6\n19.4\n194\n3525\nfemale\n2009\n\n\nChinstrap\nDream\n51.9\n19.5\n206\n3950\nmale\n2009\n\n\nChinstrap\nDream\n46.8\n16.5\n189\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n45.7\n17.0\n195\n3650\nfemale\n2009\n\n\nChinstrap\nDream\n55.8\n19.8\n207\n4000\nmale\n2009\n\n\nChinstrap\nDream\n43.5\n18.1\n202\n3400\nfemale\n2009\n\n\nChinstrap\nDream\n49.6\n18.2\n193\n3775\nmale\n2009\n\n\nChinstrap\nDream\n50.8\n19.0\n210\n4100\nmale\n2009\n\n\nChinstrap\nDream\n50.2\n18.7\n198\n3775\nfemale\n2009"
  },
  {
    "objectID": "slides/01-welcome-slides.html#example-3.2-prices-of-diamonds",
    "href": "slides/01-welcome-slides.html#example-3.2-prices-of-diamonds",
    "title": "Welcome to Stat120!",
    "section": "Example 3.2: Prices of diamonds",
    "text": "Example 3.2: Prices of diamonds"
  },
  {
    "objectID": "slides/01-welcome-slides.html#example-3.3-is-there-a-sprinting-gene",
    "href": "slides/01-welcome-slides.html#example-3.3-is-there-a-sprinting-gene",
    "title": "Welcome to Stat120!",
    "section": "Example 3.3: Is there a “Sprinting Gene”?",
    "text": "Example 3.3: Is there a “Sprinting Gene”?\nA gene called ACTN3 encodes a protein which functions in fast-twitch muscles. Some people have a variant of this gene that cannot yield this protein. To address the question of whether this gene is associated with sprinting ability, geneticists tested people from three different groups: world-class sprinters, world-class marathon runners, and a control group of non-athletes. In the sames tested, 6% of the sprinters had the gene variant, compared with 18% of non-athletes and 24% of the marathon runners."
  },
  {
    "objectID": "slides/01-welcome-slides.html#upcoming",
    "href": "slides/01-welcome-slides.html#upcoming",
    "title": "Welcome to Stat120!",
    "section": "Upcoming",
    "text": "Upcoming\n\nHW1 is posted on moodle (due on Friday)\nVideo posted to watch before Wednesday’s class"
  },
  {
    "objectID": "slides/02-slides.html#today",
    "href": "slides/02-slides.html#today",
    "title": "02: Sampling",
    "section": "Today:",
    "text": "Today:\n\nA pep talk\nMeet your groups!\nIntro to data/Notes 01\nSamples and Populations\nSampling/RStudio Activity"
  },
  {
    "objectID": "slides/02-slides.html#what-makes-you-nervous-about-this-class",
    "href": "slides/02-slides.html#what-makes-you-nervous-about-this-class",
    "title": "02: Sampling",
    "section": "What makes you nervous about this class?",
    "text": "What makes you nervous about this class?"
  },
  {
    "objectID": "slides/02-slides.html#have-you-taken-a-stats-class-before",
    "href": "slides/02-slides.html#have-you-taken-a-stats-class-before",
    "title": "02: Sampling",
    "section": "Have you taken a stats class before?",
    "text": "Have you taken a stats class before?"
  },
  {
    "objectID": "slides/02-slides.html#how-familiar-are-you-with-the-following-tools",
    "href": "slides/02-slides.html#how-familiar-are-you-with-the-following-tools",
    "title": "02: Sampling",
    "section": "How familiar are you with the following tools?",
    "text": "How familiar are you with the following tools?"
  },
  {
    "objectID": "slides/02-slides.html#consider-the-following-research-questions",
    "href": "slides/02-slides.html#consider-the-following-research-questions",
    "title": "02: Sampling",
    "section": "Consider the following research questions:",
    "text": "Consider the following research questions:\n\nWhat is the average mercury content of swordfish in the Atlantic Ocean?\nOver the last five years, what is the average time to complete a degree for undergraduates in Minnesota? How does it compare to other states?\nDoes a new drug reduce the heart attack rate in patients with severe heart disease?"
  },
  {
    "objectID": "slides/02-slides.html#possible-responses",
    "href": "slides/02-slides.html#possible-responses",
    "title": "02: Sampling",
    "section": "3 Possible Responses:",
    "text": "3 Possible Responses:\n\nA man on the news got mercury poisoning from eating swordfish, so it must be dangerously high.\nI met two students who took less than 4 years to graduate, so it must take less time to graduate in Minnesota than in other states.\nMy friend’s father had a heart attack after taking the new drug for six months, so it must not work"
  },
  {
    "objectID": "slides/02-slides.html#the-big-picture",
    "href": "slides/02-slides.html#the-big-picture",
    "title": "02: Sampling",
    "section": "The big picture",
    "text": "The big picture\nThe ultimate goal of statistics is to learn about a population using a subset of that population. But, populations are hard (sometimes impossible!) to measure."
  },
  {
    "objectID": "slides/02-slides.html#spectrum-of-samples",
    "href": "slides/02-slides.html#spectrum-of-samples",
    "title": "02: Sampling",
    "section": "Spectrum of Samples",
    "text": "Spectrum of Samples"
  },
  {
    "objectID": "slides/02-slides.html#definitions",
    "href": "slides/02-slides.html#definitions",
    "title": "02: Sampling",
    "section": "Definitions",
    "text": "Definitions\n\n\n\nPopulation\n\n\nIncludes all units of interest\n\n\n\n\n\n\nSample\n\n\nSubset of the population\n\n\n\n\n\n\nStatistical Inference\n\n\nUsing a sample to learn about the population\n\n\n\n\n\n\nParameters and Statistics\n\n\nParameters are quantities that describe the population (like a mean). Statistics are corresponding quantities that describe a sample."
  },
  {
    "objectID": "slides/02-slides.html#identify-the-sample-mean-and-claimed-population-mean",
    "href": "slides/02-slides.html#identify-the-sample-mean-and-claimed-population-mean",
    "title": "02: Sampling",
    "section": "Identify the sample mean and (claimed) population mean",
    "text": "Identify the sample mean and (claimed) population mean\n\n\nAmerican households spent an average of about $52 in 2007 on Halloween merchandise such as costumes, decorations, and candy. To see if this number had changed, researchers conducted a new survey in 2008 before industry numbers were reported. The survey included 1,500 households and found that average Halloween spending was $58 per household.\n\n\nThe average GPA of students in 2001 at a private university was 3.37. A survey on a sample of 203 students from this university yielded an average GPA of 3.59 a decade later.\n\n\nA recent article in a college newspaper stated that college students get an average of 5.5 hours of sleep each night. A student who was skeptical about this value decided to conduct a survey by randomly sampling 25 students. On average, the sampled students slept 6.25 hours per night"
  },
  {
    "objectID": "slides/02-slides.html#whats-wrong",
    "href": "slides/02-slides.html#whats-wrong",
    "title": "02: Sampling",
    "section": "What’s wrong?",
    "text": "What’s wrong?\nI’m interested in how satisfied the Carleton community is with the fitness center. I decide I need a sample size of 100, so at 6am one morning, I stand outside the entrance ask the first 100 people who exit whether or not they enjoyed their workout. They all said yes, so I conclude the fitness center is a perfect facility."
  },
  {
    "objectID": "slides/02-slides.html#whats-wrong-1",
    "href": "slides/02-slides.html#whats-wrong-1",
    "title": "02: Sampling",
    "section": "What’s wrong?",
    "text": "What’s wrong?\n75% of online reviews for a product are negative, so 75% of buyers are dissatisfied with the product."
  },
  {
    "objectID": "slides/02-slides.html#section",
    "href": "slides/02-slides.html#section",
    "title": "02: Sampling",
    "section": "",
    "text": "Simple Random Sample\n\n\nAll groups of size \\(n\\) have an equal chance of being selected\n\n\n\n\n\n\nBias\n\n\nOccurs when the method of collecting data causes the sample to inaccurately represent the population"
  },
  {
    "objectID": "slides/02-slides.html#section-1",
    "href": "slides/02-slides.html#section-1",
    "title": "02: Sampling",
    "section": "",
    "text": "Undercoverage\n\n\nPart of the population has less representation in the sample\n\n\n\n\n\n\nVoluntary Response\n\n\nIndividuals choose whether or not to participate\n\n\n\n\n\n\nConvenience Sample\n\n\nSample consists of units that are “easy” to sample\n\n\n\n\n\n\nNon-response bias\n\n\nLarge fraction of the selected sample do not respond/participate"
  },
  {
    "objectID": "slides/03-slides.html#observational-studies",
    "href": "slides/03-slides.html#observational-studies",
    "title": "03: Observational Studies and Experiments",
    "section": "Observational Studies",
    "text": "Observational Studies\n\nResearchers studying the relationship between exercising and energy levels asked participants in their study how many times a week they exercise and whether they have high or low energy when they wake up in the morning.\n\n\nBased on repsonses to the exercise question, the researchers grouped people into three categories: no exercise, exercise 1-3 times per week, and exercise more than 3 times per week\n\n\nThe researchers then compared the proportions of people who said they have high energy in the mornings across the three exercise categories.\n\n\nThis is an observational study since the researchers had no control over how often people exercised.\n\n\nResults could be due to exercise habits, or it could be do to something else.\n\n\nThe most we can say is that morning energy and exercise habits are related to each other."
  },
  {
    "objectID": "slides/03-slides.html#lets-change-it-up",
    "href": "slides/03-slides.html#lets-change-it-up",
    "title": "03: Observational Studies and Experiments",
    "section": "Let’s change it up:",
    "text": "Let’s change it up:\n\nResearchers studying the relationship between exercising and energy levels randomly assigned participants in their study into three groups: no exercise, exercise 1-3 times per week, and exercise more than 3 times per week\n\n\nAfter one week, participants were asked whether they have high or low energy when they wake up in the morning.\n\n\nThe researchers then compared the proportions of people who said they have high energy in the mornings across the three exercise categories.\n\n\nIn this case, researchers have randomly assigned participants to groups: we know that any differences are not due to other underlying attributes.\n\n\nThis means we can say that more exercise causes better morning energy levels."
  },
  {
    "objectID": "slides/03-slides.html#experiments",
    "href": "slides/03-slides.html#experiments",
    "title": "03: Observational Studies and Experiments",
    "section": "Experiments",
    "text": "Experiments\n\nExplanatory Variable is manipulated by researchers\nRandom Assignment (usually)\nResponse Variable is measured\nWith random assignment, any differences in the response variable between the groups is caused by the change in the explanatory variable\nWithout random assignment, we have to be mindful of confounding/lurking variables"
  },
  {
    "objectID": "slides/03-slides.html#confounding-and-lurking-variables",
    "href": "slides/03-slides.html#confounding-and-lurking-variables",
    "title": "03: Observational Studies and Experiments",
    "section": "Confounding and Lurking Variables",
    "text": "Confounding and Lurking Variables\nIn an observational study, lurking variables are other variables that may cause any association that we observe\n\nIn an experiment, confounding variables are other variables that are related to our explanatory variable that may be causing the difference in our response variable. (for example, if different groups participate in our exercise study at different times of the year, the weather or daylight may be impacting our results)\n\n\nIn this class, we’ll use these terms interchangeably. Random assignment of the explanatory variable should “take care” of any confounding variables."
  },
  {
    "objectID": "slides/03-slides.html#what-types-of-conclusions-can-we-draw",
    "href": "slides/03-slides.html#what-types-of-conclusions-can-we-draw",
    "title": "03: Observational Studies and Experiments",
    "section": "What types of conclusions can we draw?",
    "text": "What types of conclusions can we draw?\n\n\n\n\n\n\n\n\n\nRandom Assignment\nNo Random Assignment\n\n\n\n\nRandom Sampling\nCausal conclusion, generalized to the population\nNo causal conclusion (only correlation), generalized to the population\n\n\nNo Random Sampling\nCausal conclusion for the sample\nNo causal conclusion (only correlation), no generalization to the population\n\n\n\n\nWhen we have random assignment (an experiment), correlation does equal causation.\n\n\nWhen we have a random sample, we can generalize to the population"
  },
  {
    "objectID": "slides/03-slides.html#you-should-be-comfortable-answering-the-following-questions-about-a-study-design",
    "href": "slides/03-slides.html#you-should-be-comfortable-answering-the-following-questions-about-a-study-design",
    "title": "03: Observational Studies and Experiments",
    "section": "You should be comfortable answering the following questions about a study design:",
    "text": "You should be comfortable answering the following questions about a study design:\n\nWhether it was an observational study or experiment\n\n\nif it was an observational study, identify:\n\nthe subjects studied and how they were selected\nthe parameter of interest\nthe nature and scope of the conclusion the study can reach\n\n\n\nif it was an experiment, identify:\n\nthe subjects studied\nthe explanatory variable(s) in the experiment\nthe response variable measured\nthe nature and scope of the conclusion the experiment can reach"
  },
  {
    "objectID": "slides/03-slides.html#example-swedish-study",
    "href": "slides/03-slides.html#example-swedish-study",
    "title": "03: Observational Studies and Experiments",
    "section": "Example: Swedish Study",
    "text": "Example: Swedish Study\n\nEpidemiology is the study of how and why diseases occur in the population, and Scandinavian countries are an epidemiologist’s dream. This is because everyone in those countries has a personal identification number which is used when registering for health care, education, tax, and so on, and this allows researchers to link all these different aspects of people’s lives together in a way that would be impossible (and perhaps politically controversal) in other countries. -David Spiegelhalter, The Art of Statistics, Ch 4\n\n\nLet’s look at one Scandinavian epidemiology study:\nKhanolkar AR, Ljung R, Talback M, et al. Socioeconomic position and the risk of brain tumour: a Swedish national population-based cohort study J Epidemiol Community Health 2016;70:1222-1228. link"
  },
  {
    "objectID": "slides/03-slides.html#section",
    "href": "slides/03-slides.html#section",
    "title": "03: Observational Studies and Experiments",
    "section": "",
    "text": "Background The aim was to investigate associations between different measures of socioeconomic position (SEP) and incidence of brain tumours (glioma, meningioma and acoustic neuroma) in a nationwide population-based cohort.\n\nMethods We included 4,305,265 individuals born in Sweden during 1911-1961, and residing in Sweden in 1991. Cohort members were followed from 1993 to 2010 for a first primary diagnosis of brain tumour identified from the National Cancer Register. Poisson regression was used to compute incidence rate ratios (IRR) by highest education achieved, family income, occupational group and marital status, with adjustment for age, healthcare region of residence, and time period.\n\n\nResults We identified 5735 brain tumours among men and 7101 among women during the study period. Highly educated men ( \\(\\ge3\\) years university education) had increased risk of glioma (IRR 1.22, 95% CI 1.08 to 1.37) compared to men with primary education. High income was associated with higher incidence of glioma in men (1.14, 1.01 to 1.27). Women with \\(\\ge3\\) years university education had increased risk of glioma (1.23, 1.08 to 1.40) and meningioma (1.16, 1.04 to 1.29) compared to those with primary education. Men and women in intermediate and higher non-manual occupations had increased risk of glioma compared to low manual groups. Compared to those married/cohabiting, being single or previously married/cohabiting was associated with decreased risk of glioma in men. Men in non-manual occupations had ~50% increased risk of acoustic neuroma compared to men in low manual occupations.\n\n\nConclusions We observed consistent associations between higher SEP and higher risk of glioma. Completeness of cancer registration and detection bias are potential explanations for the findings."
  },
  {
    "objectID": "slides/03-slides.html#press-office-release",
    "href": "slides/03-slides.html#press-office-release",
    "title": "03: Observational Studies and Experiments",
    "section": "Press Office Release",
    "text": "Press Office Release\n\nSource: Science Daily"
  },
  {
    "objectID": "slides/03-slides.html#popular-media-article",
    "href": "slides/03-slides.html#popular-media-article",
    "title": "03: Observational Studies and Experiments",
    "section": "Popular Media Article",
    "text": "Popular Media Article"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "activities/11-activity.html",
    "href": "activities/11-activity.html",
    "title": "11: Bootstrap Confidence Intervals with StatKey",
    "section": "",
    "text": "These problems are drawn from the textbook with the datasets built into StatKey. I want the focus today to be on the “big ideas” of bootstrap distributions and confidence intervals, without the added complexity of coding. Next time, we’ll see how to load data and create bootstrap confidence intervals in R.\n\n\n\nPart of what you need to do is choose the right menu within StatKey. For example, if you are trying to make a confidence interval for a proportion, you will need to be in the “proportion” menu under “Bootstrap confidence intervals”.\nStatkey link: https://www.lock5stat.com/StatKey/index.html\n1. Atlanta Commute times\nWhat is the average commuting time for people who live and work in the Atlanta Metropolitan Area? It’s not feasible to contact all Atlanta residents, but the US Census Bureau regularly collects data from carefully selected samples of residents in many different areas. This data is from the American Housing Survey (AHS) which contains information about housing and living conditions for samples from certain metropolitan areas. These data represent a random sample of people who live in the Atlanta metropolitan area. They include only cases where the respondent worked somewhere other than home. Variables include the time (in minutes) and distance (in miles) that respondents typically traveled on their commute to work each day as well as age and sex.\n\nWe’re going to look at the Commute Time. In StatKey, choose “Confidence Interval for Mean, Median, StDev” and then “Atlanta Commute Time”. You should see the data distribution in the “Original Sample” graph. Describe the shape, center, and spread of the data distribution.\nWhat is the relevant parameter and the best point estimate?\nGenerate 1 bootstrap sample. You should see the sample under “Bootstrap sample”. How does n, mean, median, and st dev compare to the original sample?\nGenerate 1000 bootstrap samples and describe the shape, center, and spread of the bootstrap distribution. How does it compare to the data distribution? You should be able to explain why any discrepancies exist.\nConstruct a 95% confidence interval for the average commute time and interpret it in context\n\n2. Compassionate Rats\nIn a recent study, rats showed compassion that surprised scientists. Twenty-three of the 30 rats in the study freed another trapped rat in their cage, even when chocolate served as a distraction and even when the rats would then have to share the chocolate with their freed companion. Rats did not open the cage when it was empty or when there was a stuffed animal inside, only when a fellow rat was trapped. We wish to use the sample to estimate the proportion of rats that would show empathy in this way. The data are available in the dataset CompassionateRats on StatKey.\n\nGive the relevant parameter and its best point estimate\nDescribe how you could use slips of paper to create one bootstrap statistic. How many slips of paper do you need?\nUse StatKey to create a bootstrap distribution with 500 bootstrap samples. Describe the shape, center, and spread using appropriate quantities.\nUse StatKey to create a bootstrap distribution with 20,000 bootstrap samples. How does it compare to your distribution from (c)?\nUse the standard error to find and interpret a 95% confidence interval for the proportion of rats likely to show empathy.\n\n3. Do Teen Problems Differ Based on Income Level?\nA recent study found that anxiety/depression topped the list of problems teens see among their peers. The table below shows whether they consider anxiety/depression a major problem based on household income level. We are interested in estimating the difference in proportion who think it is a major problem between the two groups.\n\n\n\nIncome\nMajor Problem\nNot Major Problem\nTotal\n\n\n&lt;$75,000\n386\n150\n536\n\n\n&gt;$75,000\n258\n126\n384\n\n\nTotal\n644\n276\n920\n\n\n\n\nWhat proportion of teens in households with an income below 75,000 think it is a major problem? What about the proportion above 75,000? \nGive notation and the value of the relevant sample statistic. Give notation for the population parameter.\nUse StatKey to find the standard error for this statistic using a bootstrap distribution. (This data is called “Teen Anxiety Depression Problem (by Income)”)\nUse the standard error to find a 99% confidence interval for the difference in proportions.\n\n4. Atlanta Commute Times (again)\nA key reason for longer commute times is having to travel a further distance. We want to see how strong the (linear) relationship is between commute distance and commute time among Atlanta residents.\n\nWhat population parameter is of interest here? \nFind the correct StatKey menu and choose the dataset “Commute Atlanta (Time as a function of Distance)”. Describe the original sample and find the appropriate sample statistic. \nGenerate a bootstrap distribution and describe the shape, center, and spread. \nConstruct a 95% confidence interval and interpret it in context."
  },
  {
    "objectID": "activities/21-2-activity.html",
    "href": "activities/21-2-activity.html",
    "title": "21.2: CLT-based Inference for Difference in Means",
    "section": "",
    "text": "When we are performing a t-test or computing a t-based confidence interval for a mean, we can use the t.test() function in R. Here is a template:\nt.test(y ~ 1, data = dataset, mu = null, direction = \"two.sided\")\nwhere\n\ny is the column name for the variable\ndataset is the name of the data set\nnull is the value of \\(\\mu\\) specified in the null hypothesis\nalternative specifies which tail corresponds to the p-value. The options are \"two.sided\", \"less\", and \"greater\".\nconf.level can be added to change the confidence level of the interval returned\n\n\nThe code below reads in the FloridaLakes dataset from class last week. Use the t.test() function to perform the CLT-based t-test to see whether the average MaxMercury is less than 1 or not. Your results should match the “by hand” results from class. (Slides here)."
  },
  {
    "objectID": "activities/21-2-activity.html#one-sample-clt-inference-in-r",
    "href": "activities/21-2-activity.html#one-sample-clt-inference-in-r",
    "title": "21.2: CLT-based Inference for Difference in Means",
    "section": "",
    "text": "When we are performing a t-test or computing a t-based confidence interval for a mean, we can use the t.test() function in R. Here is a template:\nt.test(y ~ 1, data = dataset, mu = null, direction = \"two.sided\")\nwhere\n\ny is the column name for the variable\ndataset is the name of the data set\nnull is the value of \\(\\mu\\) specified in the null hypothesis\nalternative specifies which tail corresponds to the p-value. The options are \"two.sided\", \"less\", and \"greater\".\nconf.level can be added to change the confidence level of the interval returned\n\n\nThe code below reads in the FloridaLakes dataset from class last week. Use the t.test() function to perform the CLT-based t-test to see whether the average MaxMercury is less than 1 or not. Your results should match the “by hand” results from class. (Slides here)."
  },
  {
    "objectID": "activities/21-2-activity.html#two-sample-clt-inference-in-r",
    "href": "activities/21-2-activity.html#two-sample-clt-inference-in-r",
    "title": "21.2: CLT-based Inference for Difference in Means",
    "section": "Two-sample CLT inference in R",
    "text": "Two-sample CLT inference in R\nWhen we are comparing the mean of two independent groups, we again use the t.test() function in R. Here is a template:\nt.test(y ~ x, data = dataset, mu = null, direction = \"two.sided\", paired = FALSE)\nwhere\n\ny is the column name for the response variable\nx is the column name for the explanatory (grouping) variable\ndataset is the name of the data set\nnull is the value of \\(\\mu_1 - \\mu_2\\) specified in the null hypothesis\nalternative specifies which tail corresponds to the p-value. The options are \"two.sided\", \"less\", and \"greater\".\nconf.level can be added to change the confidence level of the interval returned\nif x and y represent paired measurements, change paired to TRUE to perform a matched-pairs t-test\n\n\nResearchers Holdgate et al. (2016) studied walking behavior of elephants in North American zoos to see whether there is a difference in average distance traveled by African and Asian elephants in captivity. They put GPS loggers on 33 African elephants and 23 Asian elephants, and measured the distance (in kilometers) the elephants walked per day.\n\n\nUsing EDA, compare the distribution of distance for each species. What do you learn?\nDetermine the sample sizes, sample means, and the sample standard deviations for each group. Some starter code is below (you will need to remove the line that says eval = FALSE)\n\n\nAre the conditions met for the t-procedures to be valid for these data?\nUse R to construct a 90% confidence interval for the difference between the average walking distance of the African and Asian elephant populations. Include one-sentence interpretation of your interval. (When interpreting a confidence interval for the difference, you should always clarify the direction of subtraction and which population parameter is larger.)"
  },
  {
    "objectID": "activities/02-activity.html",
    "href": "activities/02-activity.html",
    "title": "02: Sampling",
    "section": "",
    "text": "To get started:\n\nClick the “code” button\nClick “copy to clipboard” button\nIn maize, open a new rmarkdown file (New file –&gt; Rmarkdown –&gt; (name the file 02-sampling.Rmd))\nPaste the code into the file that opened up and hit “save”\n\nOnce you have the file loaded into RStudio, you can follow the directions below.\nPress the “play” button below to run the chunk of code. This (1) loads the libraries that we need and (2) tells R to read mission_data.csv from my website folder into your R session and call it mission_data.\n\nlibrary(tidyverse)\nmission_data = read_csv(\"https://www.math.carleton.edu/aluby/data/mission_data.csv\")\n\nCheck your “environment” pane in the upper right to make sure you can see a dataset called mission_data. Try clicking it, or running View(mission_data) in the console to bring up the data viewer.\nspoiler alert: The next chunk of code computes the population mean.\n\nmean(mission_data$length)\n\n[1] 5.947802\n\n\nThe code below selects a random sample of word positions to use\n\nset.seed(091824) # Sets the random seed so we all get the same answer\nsample = sample(1:nrow(mission_data), size = 10) # selects a random sample of size 10 from the numbers 1-364\nsample # prints the random sample of numbers\n\n [1] 213 328 237 164  34 311 115 121 253 250\n\n\nThe next chunk of code slices our population to draw our sample. Note that the position variable should match the sample output above.\n\nmission_sample = mission_data %&gt;% \n  slice(sample)\n\nmission_sample\n\n# A tibble: 10 × 4\n   paragraph word     position length\n       &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1         3 be            213      2\n 2         4 of            328      2\n 3         4 the           237      3\n 4         3 carleton      164      8\n 5         1 learning       34      8\n 6         4 for           311      3\n 7         3 the           115      3\n 8         3 students      121      8\n 9         4 arts          253      4\n10         4 in            250      2\n\n\nAnd this next chunk computes the mean word length of our sample\n\nmean(mission_sample$length)\n\n[1] 4.3\n\n\nTo try other random samples, change (or remove!) the set.seed() line of code, and try re-running the rest of the code. Do you ever get a sample mean that looks like your “by hand” sample mean?\nWhen you’re done, knit this file and try uploading the PDF to gradescope. There are two questions, one for the population mean and one for a sample mean. Be sure to mark the pages so I can see your answers!"
  },
  {
    "objectID": "activities/04-activity.html",
    "href": "activities/04-activity.html",
    "title": "04: Categorical Variables + Intro to Quantitative Variables",
    "section": "",
    "text": "The lab manual data Pew contains data from a January 2014 Pew Research Center survey about the Internet. We’ll consider two variables from this survey:\n\nincome: the person’s yearly income, grouped into four categories\nvalues: an answer to the question asking if the Internet has been a “good thing”\n\nThe code chunk below loads the R packages that we need. Whenever you see this chunk in materials I give you, make sure to run it first!\n\nlibrary(tidyverse)\n\n0. Import the data into R by running the following code chunk. Click on the dataset in the environment pane to pull up the data viewer. Can you see the “spreadsheet view”?\n\npew = read_csv(\"http://www.math.carleton.edu/Stat120/RLabManual/Pew.csv\")\n\n1. The code below computes the frequency table for the values variable. Add a “pipe” (%&gt;%) and another command to answer: what proportion of respondents said that the Internet has been a good thing?\n\ntable(pew$values) \n\n\n bad good \n 140  556 \n\n\n2. Using esquisse or ggplot, make a bar plot of the counts of people who said the Internet has vs. has not been a good thing. Insert your code in the chunk below.\n3. Show the two-way table for the values and income variables. How many people from the survey had an income above $150,000 a year and thought the Internet was a bad thing?\n\ntable(pew$income, pew$values)\n\n              \n               bad good\n  0-30000       57  133\n  150000         5   64\n  30000-75000   50  206\n  75000-150000  28  153\n\n\n4. The table in part 3 shows the income categories in the wrong order (i.e., not in order of increasing income). You can fix this by changing the order of the categories of the income variable as below (see Appendix A.1 of the lab manual). Remake the table after reordering the categories.\n\npew$income &lt;- factor(pew$income, levels = c(\"0-30000\", \"30000-75000\",\n                                            \"75000-150000\", \"150000\"))\n\n5. Use esquisse or ggplot to make a stacked barplot of income and values.\n6. Your bar plot by default should show the counts of each combination. Copy and paste your bar plot code, and change geom_bar() to geom_bar(position = \"fill\"). Explain what this chunk of code did.\nStop Here and let Amanda know you’ve finished with the categorical EDA section\nA third variable in the dataset is age. The next few questions walk through how to do basic EDA for a quantitative variable.\n7. Create a histogram of the age variable using esquisse or ggplot\n8. In the empty code chunk below, run mean(pew$age) and median(pew$age). Now try mode(pew$age). What happened?\n9. Using your answers to the previous two questions, describe the distribution of age."
  },
  {
    "objectID": "activities/06-activity.html",
    "href": "activities/06-activity.html",
    "title": "06: Correlation and Intro to Regression",
    "section": "",
    "text": "This dataset gives education-related data for the 50 states and the District of Columbia. The variables are:\n\nregion: West, Northeast, Midwest, South\npop: Population, in 1,000’s\nverbal and math: average SAT verbal and math scores\ntaken: percent of students taking the SAT\nnoHS: percent of population with no high school diploma\nteachersPay: median teacher salary, in 1,000’s\n\n0. Load code libraries and the data and make sure you can view it. What is each case?\n\nlibrary(tidyverse)\nsat &lt;- read.csv(\"http://math.carleton.edu/Stat120/RLabManual/sat.csv\")\n\nWe’re going to investigate the relationship between math SAT scores (math) and the percentage of high school students who took the SAT.\n1. Before looking at the data, do expect there to be a positive, negative, or no relationship? Why?\n2. Make a scatterplot of math on the y-axis and taken on the x-axis with the line of best fit included (see notes from today for the line of code to include). What do you notice?\n3. Use the lm() command to find the equation for this line. Be careful about the X and Y variables! Interpret the slope and intercept in context.\n4. Find the correlation for this relationship.\n5. Color the scatterplot by region. What do you notice?\nThe code chunk below creates a new dataset called sat_northeast which filters to only the Northeast states (== is code for “equals”).\n\nsat_northeast &lt;- sat %&gt;%\n  filter(region == \"Northeast\")\n\n6. Make a scatterplot of math on the y-axis and taken on the x-axis with the line of best fit included.\n7. Use the lm() command to find the equation for this line. How does it compare to your line from (3)?\n8. Find the correlation for this relationship. How does it compare to the correlation for the whole dataset?\nNote: this data is adapted from Ch 3.4 of the Lab Manual. You can find most of the code solutions there if your group gets stuck!"
  },
  {
    "objectID": "activities/24-activity.html",
    "href": "activities/24-activity.html",
    "title": "24: Inference for Regression in R",
    "section": "",
    "text": "When we are fitting a linear regression model in R, we use the lm() function. Here is a template:\nlm(y ~ x, data = dataset)\nwhere\n\ny is the column name for the response variable\nx is the column name for the categorical predictor variable\ndataset is the name of the data set\n\nTo get the summary table use\nsummary(lm_mod)\nwhere lm_mod is the name of the model that you fit using lm().\nTo find confidence and prediction intervals for observations, use augment() from the broom package\naugment(lm_mod, newdata = tibble(x = ______), interval = \"none\", conf.level = .95)\nwhere\n\nlm_mod is the name of the model that you fit using lm()\nx is the column name for the categorical predictor variable\n_____ is filled in with the value of x that you want to predict\ninterval is one of “none”, “confidence”, or “prediction”\nconf.level is the confidence level for the interval (default is 0.95)\n\nWe’re going to use the dataset cereals.csv, which has nutrition data on a random sample of breakfast cereals.\n1. Load in the data and check the “spreadsheet view”. How many cereals are in the sample?\n2. We’re going to try to predict carbs per gram (carbsgram) using calories per gram (calgram). Make a scatterplot and describe the relationship you find.\n3. Find a confidence interval for the slope and report your result in context. Some starter code is below (make sure to remove eval = FALSE!)\n4. Use the starter code below to find a 90% prediction interval for a new cereal with 3.5 calories per gram. Interpret your result in context.\n5. The code below creates a confidence interval and prediction interval for all predicted values. One is shown in blue and one is shown in orange. Which is which, and how can you tell?\n6. There is one point that falls outside of the prediction interval. Is this evidence that it is an outlier? Should we remove it?\n7. The code below makes residual plots for the cereal_lm model. (Remove eval = FALSE after you have created the model). Do you have any concerns about the LINE conditions?\n8. When we include plots on posters or in papers, we want to be mindful of how much space they take up but also make sure they are readable. One way that I like to do this is by putting multiple plots side-by-side using the patchwork package. Remove eval = FALSE and run the code below. Next, run p1+p2 in the console to make the plot show up in the viewer. Click on “export” and then “save as image”. Change the dimensions to be 1200 pixels long x 400 pixels tall and save your plot with an informative file name. In order to get the plot from the RStudio Server onto your own computer, go to the “Files” tab and click on the name of the image. This should bring up a high-quality image that you can copy and paste into a text editor or embed directly. Alternatively, you can check the box next to the image and click on “more –&gt; export” to download to your computer. Submit only this image file on gradescope (1 per group)."
  },
  {
    "objectID": "activities/12-activity-sols.html",
    "href": "activities/12-activity-sols.html",
    "title": "12: Solutions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(patchwork)\nlibrary(CarletonStats)\n\nThe data set Pew.csv contains part of a survey conducted by the Pew Research Center in January 2014. One of the questions they asked was, “Overall, when you add up all the advantages and disadvantages of the internet, would you say that the internet has been mostly a good thing, a bad thing, or some of both?”\nThe variable values codes the response as “good” if the respondent said the internet has been a good thing and “bad” otherwise (this includes “a bad thing” and “some of both”).\nLet’s see if this differs based on whether the respondent is 50 years or older or not.\n\nPew &lt;- read.csv(\"http://math.carleton.edu/Stat120/RLabManual/Pew.csv\")\n\nPew &lt;- Pew |&gt;\n  mutate(\n    over = ifelse(age &gt;=50, \"over50\", \"under50\"),\n    over2 = ifelse(age &gt;=50, 1, 0)\n  )\n\n1. Create an appropriate visualization of values conditioned on over. Does it appear that the proportion of over 50 year olds that said the internet has been a good thing is approximately the same as the under 50’s?\n\n\n\n\n\n\nTipSolution\n\n\n\nYou can tell they are not exactly equal, but the percentage who say it’s been a good thing appear pretty similar across the two age groups\n\nggplot(Pew, aes(y = over, fill = values)) + \n  geom_bar(position = \"fill\") \n\n\n\n\n\n\n\n\n\n\n2. Compute the exact proportions for each age group.\n\n\n\n\n\n\nTipSolution\n\n\n\n\ntable(Pew$over, Pew$values) |&gt;\n  proportions(2)\n\n         \n                bad      good\n  over50  0.5714286 0.5125899\n  under50 0.4285714 0.4874101\n\n\n\n\n3. In order to use the boot() command, the response must be coded as a binary variable of 0’s and 1’s (instead of the names of the categories). Pull up the “spreadsheet view” of the data and confirm that values and values2 contain the same information stored in a different form.\n\n\n\n\n\n\nTipSolution\n\n\n\nConfirmed. good = 1 and bad = 0\n\nPew |&gt;\n  select(values, values2) |&gt;\n  unique()\n\n  values values2\n1   good       1\n2    bad       0\n\n\n\n\n\n\n\n\n\n\nTipMeans vs Proportions?\n\n\n\nSince the values are 0’s and 1’s, when you compute the mean, you will be computing an expression of the form\n\\[ \\frac{1 + 1 + 0 + 1 + 0 +... +0}{n}\\] which is equivalent to the proportion of 1’s. This means that we can treat proportions as means. Yay!\n\n\n4. Create a bootstrap distribution of the difference in proportions and give a sentence interpreting the 95% percentile interval. Use the variable values2, which is behavior recoded so that 1 = “good”, 0 = “bad”.\n\n\n\n\n\n\nTipSolution\n\n\n\nI am 95% confident that the true difference in proportions between the two age groups is between -0.1 and 0.02.\n\nboot(values2 ~ over, data = Pew)\n\n\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : over50 - under50 = -0.03791 \n Mean of bootstrap distribution: -0.03788 \n Standard error of bootstrap distribution: 0.03022 \n\n Bootstrap percentile interval\n       2.5%       97.5% \n-0.09769482  0.02110665 \n\n        *--------------*\n\n\n\n\n\n\n\n\n\n\n\n5. Compute the 95% confidence interval based on the 95% rule. How does it compare to the percentile interval?\n\n\n\n\n\n\nTipSolution\n\n\n\n\\[-.0379 \\pm2\\times  0.03 = [-0.0979 , 0.0221] \\]\nIt is extremely similar."
  },
  {
    "objectID": "activities/15-activity.html",
    "href": "activities/15-activity.html",
    "title": "15: Hypothesis Tests",
    "section": "",
    "text": "Do heart attack victims have higher cholesterol levels than non-heart attack victims? The dataset Cholesterol.csv has cholesterol measurements (mg/dL) for a sample of heart attack victims (4 days after the heart attack) and a sample of non-heart attack victims.\n0. Load the data and check the “spreadsheet view”. What is each case? How many variables are there?\n1. Create an appropriate graph to answer the research question.\n2. Without performing a formal statistical test Does there appear to be evidence of a difference in cholesterol levels between the control group and the heart attack group?\n3. Write out appropriate null and alternative hypotheses using the original research question.\n4. Use the permTest() command in R to test your hypotheses. (Make sure to include seed()!)\n5. Report the test statistic and p-value from the R output.\n6. Make a formal statistical decision and report your conclusion in context.\n7. What type of error could you have made in (6)? Do you know the probability that an error occurred?\nWhen you’re done: Let Amanda know.\nNote: This is based on Lab Manual Ch5 #7\n8. True or False? If false, explain why or correct the statement.\n\nIf a p-value is 10%, there is a 1 in 10 chance the null hypothesis is correct\nWhen a p-value is extremely small, the result is extremely important\nA small p-value means that the result could not possibly have been due to chance\nA big p-value means that you do not have strong evidence against the null hypothesis\nA p-value is the probability of getting a result more in favor of the alternative hypothesis than the result that you observed, assuming the null hypothesis is true\nA p-value is the probability of getting a result more in favor of the alternative hypothesis than the result that you observed, assuming the alternative hypothesis is true"
  }
]